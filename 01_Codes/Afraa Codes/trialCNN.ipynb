{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"train_test_DDR_APTOS.csv\")\n",
    "\n",
    "filtered_data = data[data[\"Data_source\"] == \"DDR\"]\n",
    "# Split the dataset into training and testing sets\n",
    "train_data = filtered_data[filtered_data[\"Split\"] == \"Train\"]\n",
    "test_data = filtered_data[filtered_data[\"Split\"] == \"Test\"]\n",
    "\n",
    "# Define output directories\n",
    "preprocessed_output_dir_train = \"preprocessed_images_train/\"\n",
    "cropped_output_dir_train = \"cropped_images_train/\"\n",
    "normalized_output_dir_train = \"normalized_images_train/\"\n",
    "preprocessed_output_dir_test = \"preprocessed_images_test/\"\n",
    "cropped_output_dir_test = \"cropped_images_test/\"\n",
    "normalized_output_dir_test = \"normalized_images_test/\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(preprocessed_output_dir_train, exist_ok=True)\n",
    "os.makedirs(cropped_output_dir_train, exist_ok=True)\n",
    "os.makedirs(normalized_output_dir_train, exist_ok=True)\n",
    "os.makedirs(preprocessed_output_dir_test, exist_ok=True)\n",
    "os.makedirs(cropped_output_dir_test, exist_ok=True)\n",
    "os.makedirs(normalized_output_dir_test, exist_ok=True)\n",
    "\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image_path, output_dir):\n",
    "    # Load and resize the image to 512x512\n",
    "    resized_image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(resized_image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
    "    l_eq = clahe.apply(l)\n",
    "\n",
    "    # Merge back LAB channels\n",
    "    lab_eq = cv2.merge((l_eq, a, b))\n",
    "    enhanced_image = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Image noise removal using Gaussian filter\n",
    "    filtered_image = cv2.GaussianBlur(enhanced_image, (5, 5), 0)\n",
    "\n",
    "    # Save the preprocessed image\n",
    "    image_name = os.path.basename(image_path)\n",
    "    output_path = os.path.join(output_dir, image_name)\n",
    "    cv2.imwrite(output_path, filtered_image)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def crop_image(img, threshold=15, resize_flag=False, desired_size=(512, 512)):\n",
    "    img_np = np.array(img)\n",
    "    x_dim = img_np.shape[0]\n",
    "    y_dim = img_np.shape[1]\n",
    "    pixel_sums = img_np.sum(axis=2)\n",
    "    x_arr = pixel_sums.sum(axis=1)\n",
    "    y_arr = pixel_sums.sum(axis=0)\n",
    "    x_start = np.where(x_arr > threshold * y_dim)[0][0]\n",
    "    x_end = np.where(x_arr > threshold * y_dim)[0][-1]\n",
    "    y_start = np.where(y_arr > threshold * x_dim)[0][0]\n",
    "    y_end = np.where(y_arr > threshold * x_dim)[0][-1]\n",
    "    new_img = img_np[x_start:x_end, y_start:y_end]\n",
    "    new_img = Image.fromarray(new_img)\n",
    "    if resize_flag:\n",
    "        new_img = new_img.resize(desired_size)\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def normalize_image(img):\n",
    "    # Convert image to numpy array\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Calculate mean and standard deviation (std) channel-wise\n",
    "    mean_channels = np.mean(img_np, axis=(0, 1))\n",
    "    std_channels = np.std(img_np, axis=(0, 1))\n",
    "\n",
    "    # Normalize each channel separately\n",
    "    normalized_image = np.zeros_like(img_np, dtype=np.float32)\n",
    "    for channel in range(img_np.shape[2]):\n",
    "        normalized_image[:, :, channel] = (\n",
    "            img_np[:, :, channel] - mean_channels[channel]\n",
    "        ) / std_channels[channel]\n",
    "\n",
    "    # Scale values to be within [0, 255]\n",
    "    normalized_image = (\n",
    "        (normalized_image - np.min(normalized_image))\n",
    "        / (np.max(normalized_image) - np.min(normalized_image))\n",
    "        * 255\n",
    "    )\n",
    "\n",
    "    # Clip and return the normalized image\n",
    "    normalized_image = np.clip(normalized_image, 0, 255)\n",
    "    return normalized_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for img_name, label in zip(train_data[\"Image_ID\"], train_data[\"Retinopathy_Grade\"]):\n",
    "    # Load the image\n",
    "    image_path = \"train_new/\" + img_name\n",
    "\n",
    "    # Preprocess the image\n",
    "    preprocessed_img_path = preprocess_image(image_path, preprocessed_output_dir_train)\n",
    "\n",
    "    # Crop and resize the image\n",
    "    preprocessed_img = Image.open(preprocessed_img_path)\n",
    "    cropped_resized_img = crop_image(\n",
    "        preprocessed_img, resize_flag=True, desired_size=(512, 512)\n",
    "    )\n",
    "\n",
    "    # Save cropped image\n",
    "    cropped_img_path = os.path.join(cropped_output_dir_train, img_name)\n",
    "    cropped_resized_img.save(cropped_img_path)\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save normalized image\n",
    "    normalized_img_path = os.path.join(normalized_output_dir_train, img_name)\n",
    "    cv2.imwrite(normalized_img_path, cv2.cvtColor(normalized_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Append to X_train and y_train\n",
    "    X_train.append(normalized_img)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for img_name, label in zip(test_data[\"Image_ID\"], test_data[\"Retinopathy_Grade\"]):\n",
    "    # Load the image\n",
    "    image_path = \"test_new/\" + img_name\n",
    "\n",
    "    # Preprocess the image\n",
    "    preprocessed_img_path = preprocess_image(image_path, preprocessed_output_dir_test)\n",
    "\n",
    "    # Crop and resize the image\n",
    "    preprocessed_img = Image.open(preprocessed_img_path)\n",
    "    cropped_resized_img = crop_image(\n",
    "        preprocessed_img, resize_flag=True, desired_size=(512, 512)\n",
    "    )\n",
    "\n",
    "    # Save cropped image\n",
    "    cropped_img_path = os.path.join(cropped_output_dir_test, img_name)\n",
    "    cropped_resized_img.save(cropped_img_path)\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save normalized image\n",
    "    normalized_img_path = os.path.join(normalized_output_dir_test, img_name)\n",
    "    cv2.imwrite(normalized_img_path, cv2.cvtColor(normalized_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Append to X_test and y_test\n",
    "    X_test.append(normalized_img)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IGNORE THIS PART ONWARDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"/workspaces/Diabetic-Retinopathy/train_test_DDR_APTOS.csv\")\n",
    "\n",
    "filtered_data = data[data[\"Data_source\"] == \"DDR\"]\n",
    "# Split the dataset into training and testing sets\n",
    "train_data = filtered_data[filtered_data[\"Split\"] == \"Train\"]\n",
    "test_data = filtered_data[filtered_data[\"Split\"] == \"Test\"]\n",
    "\n",
    "# Define output directories\n",
    "normalized_output_dir_train = (\n",
    "    \"/workspaces/Diabetic-Retinopathy/normalized_images_train/\"\n",
    ")\n",
    "normalized_output_dir_test = \"/workspaces/Diabetic-Retinopathy/normalized_images_test/\"\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for img_name, label in zip(train_data[\"Image_ID\"], train_data[\"Retinopathy_Grade\"]):\n",
    "    # Load the image\n",
    "    print(img_name)\n",
    "    image_path = normalized_output_dir_train + img_name\n",
    "    print(image_path)\n",
    "    normalized_img = cv2.imread(image_path)\n",
    "\n",
    "    # Append to X_train and y_train\n",
    "    X_train.append(normalized_img)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for img_name, label in zip(train_data[\"Image_ID\"], train_data[\"Retinopathy_Grade\"]):\n",
    "    # Load the image\n",
    "    image_path = normalized_output_dir_test + img_name\n",
    "    normalized_img = cv2.imread(image_path)\n",
    "\n",
    "    # Append to X_test and y_test\n",
    "    X_test.append(normalized_img)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    BatchNormalization,\n",
    "    ZeroPadding2D,\n",
    "    Activation,\n",
    "    Dropout,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "# Define the CNN512 model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer (Zero Padding)\n",
    "model.add(ZeroPadding2D(padding=(2, 2), input_shape=(512, 512, 3)))\n",
    "\n",
    "# Layer 1, 2, 3\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 4\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 5, 6, 7\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 8\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 9, 10, 11\n",
    "model.add(Conv2D(96, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 12\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 13, 14, 15\n",
    "model.add(Conv2D(96, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 17, 18, 19\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 20\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 21, 22, 23\n",
    "model.add(Conv2D(200, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 24\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 25\n",
    "model.add(Flatten())\n",
    "\n",
    "# Layer 26 (Dropout)\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 27, 28, 29\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 30 (Dropout)\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 31, 32, 33\n",
    "model.add(Dense(500))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 34 (Dropout)\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 35\n",
    "model.add(Dense(4, activation=\"softmax\"))  # Assuming 4 classes for Retinopathy grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "# Define other training parameters\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "learning_rate = 1e-1\n",
    "momentum = 0.9\n",
    "\n",
    "# Compile the model\n",
    "optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Get class weights\n",
    "class_weights = compute_class_weight(\n",
    "    \"balanced\",\n",
    "    np.unique(train_data[\"Retinopathy_Grade\"]),\n",
    "    train_data[\"Retinopathy_Grade\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Define learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 25:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * math.exp(-0.1)\n",
    "\n",
    "\n",
    "scheduler = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Define data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=35,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.25, 1.25],\n",
    ")\n",
    "\n",
    "# Fit the model with augmented data\n",
    "history = model.fit(\n",
    "    datagen.flow(\n",
    "        X_train, y_train, batch_size=20 * batch_size\n",
    "    ),  # Apply augmentation 20 times\n",
    "    steps_per_epoch=len(X_train)\n",
    "    / (20 * batch_size),  # Adjust steps_per_epoch accordingly\n",
    "    epochs=epochs,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[scheduler],\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
