{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 04:23:47.612044: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 04:23:47.615384: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 04:23:47.656248: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 04:23:48.611221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set seeds to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)  # For multi-GPU setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"../../aws_s3/DDR+APTOS_TRAIN_TEST/train_test_DDR_APTOS.csv\")\n",
    "\n",
    "filtered_data = data[data[\"Data_source\"] == \"DDR\"]\n",
    "# Split the dataset into training and testing sets\n",
    "train_data = filtered_data[filtered_data[\"Split\"] == \"Train\"]\n",
    "test_data = filtered_data[filtered_data[\"Split\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directories\n",
    "luminosity_output_dir_train = \"luminosity_images_train/\"\n",
    "cropped_output_dir_train = \"cropped_images_train/\"\n",
    "normalized_output_dir_train = \"normalized_images_train/\"\n",
    "luminosity_output_dir_test = \"luminosity_images_test/\"\n",
    "cropped_output_dir_test = \"cropped_images_test/\"\n",
    "normalized_output_dir_test = \"normalized_images_test/\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(luminosity_output_dir_train, exist_ok=True)\n",
    "os.makedirs(cropped_output_dir_train, exist_ok=True)\n",
    "os.makedirs(normalized_output_dir_train, exist_ok=True)\n",
    "os.makedirs(luminosity_output_dir_test, exist_ok=True)\n",
    "os.makedirs(cropped_output_dir_test, exist_ok=True)\n",
    "os.makedirs(normalized_output_dir_test, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# luminosity and noise removal function\n",
    "def luminosity_image(image_path, output_dir):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
    "    l_eq = clahe.apply(l)\n",
    "\n",
    "    # Merge back LAB channels\n",
    "    lab_eq = cv2.merge((l_eq, a, b))\n",
    "    enhanced_image = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Image noise removal using Gaussian filter\n",
    "    filtered_image = cv2.GaussianBlur(enhanced_image, (5, 5), 0)\n",
    "\n",
    "    # Save the preprocessed image\n",
    "    image_name = os.path.basename(image_path)\n",
    "    output_path = os.path.join(output_dir, image_name)\n",
    "    cv2.imwrite(output_path, filtered_image)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, threshold=20, resize_flag=False, desired_size=(512, 512)):\n",
    "    img_np = np.array(img)\n",
    "    x_dim = img_np.shape[0]\n",
    "    y_dim = img_np.shape[1]\n",
    "    pixel_sums = img_np.sum(axis=2)\n",
    "    x_arr = pixel_sums.sum(axis=1)\n",
    "    y_arr = pixel_sums.sum(axis=0)\n",
    "    x_start = np.where(x_arr > threshold * y_dim)[0][0]\n",
    "    x_end = np.where(x_arr > threshold * y_dim)[0][-1]\n",
    "    y_start = np.where(y_arr > threshold * x_dim)[0][0]\n",
    "    y_end = np.where(y_arr > threshold * x_dim)[0][-1]\n",
    "    new_img = img_np[x_start:x_end, y_start:y_end]\n",
    "    new_img = Image.fromarray(new_img)\n",
    "    if resize_flag:\n",
    "        new_img = new_img.resize(desired_size)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(img):\n",
    "    # Convert image to numpy array\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Calculate mean and standard deviation (std) channel-wise\n",
    "    mean_channels = np.mean(img_np, axis=(0, 1))\n",
    "    std_channels = np.std(img_np, axis=(0, 1))\n",
    "\n",
    "    # Normalize each channel separately\n",
    "    normalized_image = np.zeros_like(img_np, dtype=np.float32)\n",
    "    for channel in range(img_np.shape[2]):\n",
    "        normalized_image[:, :, channel] = (\n",
    "            img_np[:, :, channel] - mean_channels[channel]\n",
    "        ) / std_channels[channel]\n",
    "\n",
    "    # Scale values to be within [0, 255]\n",
    "    normalized_image = (\n",
    "        (normalized_image - np.min(normalized_image))\n",
    "        / (np.max(normalized_image) - np.min(normalized_image))\n",
    "        * 255\n",
    "    )\n",
    "\n",
    "    # Clip and return the normalized image\n",
    "    normalized_image = np.clip(normalized_image, 0, 255)\n",
    "    return normalized_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 34 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Crop and resize the image\u001b[39;00m\n\u001b[1;32m     32\u001b[0m luminosity_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(luminosity_img_path)\n\u001b[0;32m---> 33\u001b[0m cropped_resized_img \u001b[38;5;241m=\u001b[39m \u001b[43mcrop_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mluminosity_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Save cropped image\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m img_name:\n",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m, in \u001b[0;36mcrop_image\u001b[0;34m(img, threshold, resize_flag, desired_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrop_image\u001b[39m(img, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, resize_flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, desired_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m512\u001b[39m)):\n\u001b[0;32m----> 2\u001b[0m     img_np \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     x_dim \u001b[38;5;241m=\u001b[39m img_np\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m     y_dim \u001b[38;5;241m=\u001b[39m img_np\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/Image.py:696\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    694\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 696\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/Image.py:755\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m    753\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m--> 755\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "\n",
    "# Function to get the correct image path with extension\n",
    "def get_image_path(base_dir, img_name):\n",
    "    for ext in [\"jpg\", \"png\"]:\n",
    "        if \"jpg\" in img_name or \"png\" in img_name:\n",
    "            temp_path = f\"{base_dir}/{img_name}\"\n",
    "        else:\n",
    "            temp_path = f\"{base_dir}/{img_name}.{ext}\"\n",
    "        if os.path.exists(temp_path):\n",
    "            return temp_path\n",
    "    return None  # Return None if no file is found\n",
    "\n",
    "\n",
    "# Load and preprocess each image\n",
    "for index, row in train_data.iterrows():\n",
    "    img_name, label = row[\"Image_ID\"], row[\"Retinopathy_Grade\"]\n",
    "    image_path = get_image_path(\n",
    "        \"../../aws_s3/DDR+APTOS_TRAIN_TEST/train_new\", img_name\n",
    "    )  # Dynamically get the correct image path\n",
    "\n",
    "    if image_path is None:\n",
    "        print(f\"Image file for {img_name} not found in JPG or PNG format.\")\n",
    "        continue  # Skip this iteration if the file doesn't exist\n",
    "\n",
    "    # Change Luminosity and do noise removal for the image\n",
    "    luminosity_img_path = luminosity_image(image_path, luminosity_output_dir_train)\n",
    "\n",
    "    # Crop and resize the image\n",
    "    luminosity_img = Image.open(luminosity_img_path)\n",
    "    cropped_resized_img = crop_image(\n",
    "        luminosity_img, resize_flag=True, desired_size=(512, 512)\n",
    "    )\n",
    "\n",
    "    # Save cropped image\n",
    "    # if \"jpg\" in img_name:\n",
    "    #     cropped_img_name = f\"{img_name}_{index+1}.jpg\"\n",
    "    # elif \"png\" in img_name:\n",
    "    #     cropped_img_name = f\"{img_name}_{index+1}.png\"\n",
    "    cropped_img_name = f\"{img_name}_{index+1}.jpg\"\n",
    "    cropped_img_path = os.path.join(cropped_output_dir_train, cropped_img_name)\n",
    "    cropped_resized_img.save(cropped_img_path)\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save normalized image\n",
    "    # if \"jpg\" in img_name:\n",
    "    #     normalized_img_name = f\"norm_{img_name}_{index+1}.jpg\"\n",
    "    # elif \"png\" in img_name:\n",
    "    #     normalized_img_name = f\"norm_{img_name}_{index+1}.png\"\n",
    "    normalized_img_name = f\"norm_{img_name}_{index+1}.jpg\"\n",
    "    normalized_img_path = os.path.join(normalized_output_dir_train, normalized_img_name)\n",
    "    cv2.imwrite(normalized_img_path, cv2.cvtColor(normalized_img, cv2.COLOR_RGB2BGR))\n",
    "    X_train.append(normalized_img)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for index, row in test_data.iterrows():\n",
    "    img_name, label = row[\"Image_ID\"], row[\"Retinopathy_Grade\"]\n",
    "    image_path = get_image_path(\n",
    "        \"../../aws_s3/DDR+APTOS_TRAIN_TEST/test_new\", img_name\n",
    "    )  # Dynamically get the correct image path\n",
    "\n",
    "    if image_path is None:\n",
    "        print(f\"Image file for {img_name} not found in JPG or PNG format.\")\n",
    "        continue  # Skip this iteration if the file doesn't exist\n",
    "\n",
    "    # Preprocess the image\n",
    "    luminosity_img_path = luminosity_image(image_path, luminosity_output_dir_test)\n",
    "\n",
    "    # Crop and resize the image\n",
    "    luminosity_img = Image.open(luminosity_img_path)\n",
    "    cropped_resized_img = crop_image(\n",
    "        luminosity_img, resize_flag=True, desired_size=(512, 512)\n",
    "    )\n",
    "\n",
    "    # Save cropped image\n",
    "    cropped_img_name = f\"{img_name}_{index+1}.jpg\"\n",
    "    cropped_img_path = os.path.join(cropped_output_dir_test, cropped_img_name)\n",
    "    cropped_resized_img.save(cropped_img_path)\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save normalized image\n",
    "    normalized_img_name = f\"norm_{img_name}_{index+1}.jpg\"\n",
    "    normalized_img_path = os.path.join(normalized_output_dir_test, normalized_img_name)\n",
    "    cv2.imwrite(normalized_img_path, cv2.cvtColor(normalized_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Append to X_test and y_test\n",
    "    X_test.append(normalized_img)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN512 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    BatchNormalization,\n",
    "    ZeroPadding2D,\n",
    "    Activation,\n",
    "    Dropout,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "# Define the CNN512 model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer (Zero Padding)\n",
    "model.add(ZeroPadding2D(padding=(2, 2), input_shape=(512, 512, 3)))\n",
    "\n",
    "# Layer 1, 2, 3\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 4\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 5, 6, 7\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 8\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 9, 10, 11\n",
    "model.add(Conv2D(96, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 12\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 13, 14, 15\n",
    "model.add(Conv2D(96, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 17, 18, 19\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 20\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 21, 22, 23\n",
    "model.add(Conv2D(200, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 24\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 25\n",
    "model.add(Flatten())\n",
    "\n",
    "# Layer 26 (Dropout)\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 27, 28, 29\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 30 (Dropout)\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 31, 32, 33\n",
    "model.add(Dense(500))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 34 (Dropout)\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 35\n",
    "model.add(Dense(4, activation=\"softmax\"))  # Assuming 4 classes for Retinopathy grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# base learning rate\n",
    "base_learning_rate = 1e-4\n",
    "# maximum learning rate\n",
    "max_learning_rate = 1e-2\n",
    "\n",
    "# Create an instance of SGD optimizer with initial learning rate\n",
    "optimizer = SGD(learning_rate=base_learning_rate, momentum=0.9)\n",
    "\n",
    "# create class weight\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "\n",
    "# create triangular schedule\n",
    "def triangular_schedule(epoch):\n",
    "    \"\"\"Triangular learning rate scheduler.\"\"\"\n",
    "    cycle_length = 10  # Define the length of a cycle\n",
    "    cycle = math.floor(1 + epoch / (2 * cycle_length))\n",
    "    x = abs(epoch / cycle_length - 2 * cycle + 1)\n",
    "    lr = base_learning_rate + (max_learning_rate - base_learning_rate) * max(0, (1 - x))\n",
    "    return lr\n",
    "\n",
    "\n",
    "# When fitting the model, include the learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(triangular_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"Fitting the top layer of the model\")\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=4,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test dataset evaluation\")\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
