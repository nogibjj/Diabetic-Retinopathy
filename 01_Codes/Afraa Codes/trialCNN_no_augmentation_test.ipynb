{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 07:00:50.676206: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 07:00:50.865163: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-13 07:00:51.735760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-13 07:00:51.735893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-13 07:00:51.735914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set seeds to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)  # For multi-GPU setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"../../aws_s3/DDR+APTOS_TRAIN_TEST/train_test_DDR_APTOS.csv\")\n",
    "\n",
    "filtered_data = data[data[\"Data_source\"] == \"DDR\"]\n",
    "# Split the dataset into training and testing sets\n",
    "train_data = filtered_data[filtered_data[\"Split\"] == \"Train\"]\n",
    "test_data = filtered_data[filtered_data[\"Split\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directories\n",
    "luminosity_output_dir_train = \"luminosity_images_train/\"\n",
    "cropped_output_dir_train = \"cropped_images_train/\"\n",
    "normalized_output_dir_train = \"normalized_images_train/\"\n",
    "luminosity_output_dir_test = \"luminosity_images_test/\"\n",
    "cropped_output_dir_test = \"cropped_images_test/\"\n",
    "normalized_output_dir_test = \"normalized_images_test/\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(luminosity_output_dir_train, exist_ok=True)\n",
    "os.makedirs(cropped_output_dir_train, exist_ok=True)\n",
    "os.makedirs(normalized_output_dir_train, exist_ok=True)\n",
    "os.makedirs(luminosity_output_dir_test, exist_ok=True)\n",
    "os.makedirs(cropped_output_dir_test, exist_ok=True)\n",
    "os.makedirs(normalized_output_dir_test, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def luminosity_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
    "    l_eq = clahe.apply(l)\n",
    "\n",
    "    # Merge back LAB channels\n",
    "    lab_eq = cv2.merge((l_eq, a, b))\n",
    "    enhanced_image = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Image noise removal using Gaussian filter\n",
    "    filtered_image = cv2.GaussianBlur(enhanced_image, (5, 5), 0)\n",
    "\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, threshold=20, resize_flag=False, desired_size=(512, 512)):\n",
    "    img_np = np.array(img)\n",
    "    x_dim = img_np.shape[0]\n",
    "    y_dim = img_np.shape[1]\n",
    "    pixel_sums = img_np.sum(axis=2)\n",
    "    x_arr = pixel_sums.sum(axis=1)\n",
    "    y_arr = pixel_sums.sum(axis=0)\n",
    "    x_start = np.where(x_arr > threshold * y_dim)[0][0]\n",
    "    x_end = np.where(x_arr > threshold * y_dim)[0][-1]\n",
    "    y_start = np.where(y_arr > threshold * x_dim)[0][0]\n",
    "    y_end = np.where(y_arr > threshold * x_dim)[0][-1]\n",
    "    new_img = img_np[x_start:x_end, y_start:y_end]\n",
    "    new_img = Image.fromarray(new_img)\n",
    "    if resize_flag:\n",
    "        new_img = new_img.resize(desired_size)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(img):\n",
    "    # Convert image to numpy array\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Calculate mean and standard deviation (std) channel-wise\n",
    "    mean_channels = np.mean(img_np, axis=(0, 1))\n",
    "    std_channels = np.std(img_np, axis=(0, 1))\n",
    "\n",
    "    # Normalize each channel separately\n",
    "    normalized_image = np.zeros_like(img_np, dtype=np.float32)\n",
    "    for channel in range(img_np.shape[2]):\n",
    "        normalized_image[:, :, channel] = (\n",
    "            img_np[:, :, channel] - mean_channels[channel]\n",
    "        ) / std_channels[channel]\n",
    "\n",
    "    # Scale values to be within [0, 255]\n",
    "    normalized_image = (\n",
    "        (normalized_image - np.min(normalized_image))\n",
    "        / (np.max(normalized_image) - np.min(normalized_image))\n",
    "        * 255\n",
    "    )\n",
    "\n",
    "    # Clip and return the normalized image\n",
    "    normalized_image = np.clip(normalized_image, 0, 255)\n",
    "    return normalized_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 34 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 35 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 38 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "\n",
    "# Function to get the correct image path with extension\n",
    "def get_image_path(base_dir, img_name):\n",
    "    for ext in [\"jpg\", \"png\"]:\n",
    "        if \"jpg\" in img_name or \"png\" in img_name:\n",
    "            temp_path = f\"{base_dir}/{img_name}\"\n",
    "        else:\n",
    "            temp_path = f\"{base_dir}/{img_name}.{ext}\"\n",
    "        if os.path.exists(temp_path):\n",
    "            return temp_path\n",
    "    return None  # Return None if no file is found\n",
    "\n",
    "\n",
    "# Load and preprocess each image\n",
    "for index, row in train_data.iterrows():\n",
    "    img_name, label = row[\"Image_ID\"], row[\"Retinopathy_Grade\"]\n",
    "    image_path = get_image_path(\n",
    "        \"../../aws_s3/DDR+APTOS_TRAIN_TEST/train_new\", img_name\n",
    "    )  # Dynamically get the correct image path\n",
    "\n",
    "    if image_path is None:\n",
    "        print(f\"Image file for {img_name} not found in JPG or PNG format.\")\n",
    "        continue  # Skip this iteration if the file doesn't exist\n",
    "\n",
    "    # Change Luminosity and do noise removal for the image\n",
    "    filtered_image = luminosity_image(image_path)\n",
    "\n",
    "    # Crop and resize the image\n",
    "    luminosity_img = Image.fromarray(filtered_image)\n",
    "    cropped_resized_img = crop_image(\n",
    "        luminosity_img, resize_flag=True, desired_size=(512, 512)\n",
    "    )\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save cropped image\n",
    "    # if \"jpg\" in img_name:\n",
    "    #     cropped_img_name = f\"{img_name}_{index+1}.jpg\"\n",
    "    # elif \"png\" in img_name:\n",
    "    #     cropped_img_name = f\"{img_name}_{index+1}.png\"\n",
    "    # cropped_img_name = f\"{img_name}\"\n",
    "    # cropped_img_path = os.path.join(cropped_output_dir_train, cropped_img_name)\n",
    "    # cropped_resized_img.save(cropped_img_path)\n",
    "\n",
    "    # Normalize the image\n",
    "    # normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save normalized image\n",
    "    # if \"jpg\" in img_name:\n",
    "    #     normalized_img_name = f\"norm_{img_name}_{index+1}.jpg\"\n",
    "    # elif \"png\" in img_name:\n",
    "    #     normalized_img_name = f\"norm_{img_name}_{index+1}.png\"\n",
    "    normalized_img_name = f\"norm_{img_name}\"\n",
    "    normalized_img_path = os.path.join(normalized_output_dir_train, normalized_img_name)\n",
    "    cv2.imwrite(normalized_img_path, cv2.cvtColor(normalized_img, cv2.COLOR_RGB2BGR))\n",
    "    X_train.append(normalized_img)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for index, row in test_data.iterrows():\n",
    "    img_name, label = row[\"Image_ID\"], row[\"Retinopathy_Grade\"]\n",
    "    image_path = get_image_path(\n",
    "        \"../../aws_s3/DDR+APTOS_TRAIN_TEST/test_new\", img_name\n",
    "    )  # Dynamically get the correct image path\n",
    "\n",
    "    if image_path is None:\n",
    "        print(f\"Image file for {img_name} not found in JPG or PNG format.\")\n",
    "        continue  # Skip this iteration if the file doesn't exist\n",
    "\n",
    "    # Change Luminosity and do noise removal for the image\n",
    "    filtered_image = luminosity_image(image_path)\n",
    "\n",
    "    # Crop and resize the image\n",
    "    luminosity_img = Image.fromarray(filtered_image)\n",
    "    cropped_resized_img = crop_image(\n",
    "        luminosity_img, resize_flag=True, desired_size=(512, 512)\n",
    "    )\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save normalized image\n",
    "    normalized_img_name = f\"norm_{img_name}\"\n",
    "    normalized_img_path = os.path.join(normalized_output_dir_test, normalized_img_name)\n",
    "    cv2.imwrite(normalized_img_path, cv2.cvtColor(normalized_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Append to X_test and y_test\n",
    "    X_test.append(normalized_img)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained VGG16 model without the top classification layer\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(512, 512, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the pre-trained model\n",
    "model = Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(5, activation=\"softmax\"),  # Output layer with 5 classes\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",  # Use sparse categorical crossentropy for multi-class classification\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Compute class weights for imbalanced classes\n",
    "class_weights = compute_class_weight(\"balanced\", np.unique(y_train), y_train)\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN512 Model (no dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import (\n",
    "#     Conv2D,\n",
    "#     MaxPooling2D,\n",
    "#     Flatten,\n",
    "#     Dense,\n",
    "#     BatchNormalization,\n",
    "#     ZeroPadding2D,\n",
    "#     Activation,\n",
    "#     Dropout,\n",
    "# )\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# import math\n",
    "\n",
    "# # Define the CNN512 model architecture\n",
    "# model = Sequential()\n",
    "\n",
    "# # Input Layer (Zero Padding)\n",
    "# model.add(ZeroPadding2D(padding=(2, 2), input_shape=(512, 512, 3)))\n",
    "\n",
    "# # Layer 1, 2, 3\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 4\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 5, 6, 7\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 8\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 9, 10, 11\n",
    "# model.add(Conv2D(96, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 12\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 13, 14, 15\n",
    "# model.add(Conv2D(96, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 16\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 17, 18, 19\n",
    "# model.add(Conv2D(128, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 20\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 21, 22, 23\n",
    "# model.add(Conv2D(200, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 24\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 25\n",
    "# model.add(Flatten())\n",
    "\n",
    "# # Layer 26 (Dropout)\n",
    "# # model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 27, 28, 29\n",
    "# model.add(Dense(1000))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 30 (Dropout)\n",
    "# # model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 31, 32, 33\n",
    "# model.add(Dense(500))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 34 (Dropout)\n",
    "# # model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 35\n",
    "# model.add(Dense(5, activation=\"softmax\"))  # Assuming 4 classes for Retinopathy grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN512 Model (with dropout after FC layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import (\n",
    "#     Conv2D,\n",
    "#     MaxPooling2D,\n",
    "#     Flatten,\n",
    "#     Dense,\n",
    "#     BatchNormalization,\n",
    "#     ZeroPadding2D,\n",
    "#     Activation,\n",
    "#     Dropout,\n",
    "# )\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# import math\n",
    "\n",
    "# # Define the CNN512 model architecture\n",
    "# model = Sequential()\n",
    "\n",
    "# # Input Layer (Zero Padding)\n",
    "# model.add(ZeroPadding2D(padding=(2, 2), input_shape=(512, 512, 3)))\n",
    "\n",
    "# # Layer 1, 2, 3\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 4\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 5, 6, 7\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 8\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 9, 10, 11\n",
    "# model.add(Conv2D(96, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 12\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 13, 14, 15\n",
    "# model.add(Conv2D(96, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 16\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 17, 18, 19\n",
    "# model.add(Conv2D(128, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 20\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 21, 22, 23\n",
    "# model.add(Conv2D(200, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 24\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 25\n",
    "# model.add(Flatten())\n",
    "\n",
    "# # Layer 27, 28, 29\n",
    "# model.add(Dense(1000))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 31, 32, 33\n",
    "# model.add(Dense(500))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 35\n",
    "# model.add(Dense(5, activation=\"softmax\"))  # Assuming 4 classes for Retinopathy grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10019, 512, 512, 3)\n",
      "y_train shape: (10019,)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Convert to NumPy arrays if not already\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# # Check the shapes of the arrays\n",
    "# print(\"X_train shape:\", X_train.shape)\n",
    "# print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 07:23:33.368487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 07:23:33.752699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14791 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\n",
      "2024-04-13 07:23:34.208502: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7879262208 exceeds 10% of free system memory.\n",
      "2024-04-13 07:23:41.183477: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7879262208 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 105\u001b[0m\n\u001b[1;32m    102\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m LearningRateScheduler(lr_schedule)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Fit the model to the training data\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel512\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Assuming 10 epochs for training\u001b[39;49;00m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Assuming batch size of 32\u001b[39;49;00m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Learning rate scheduler callback\u001b[39;49;00m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Auto compute class weights\u001b[39;49;00m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Show training progress\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data\u001b[39;00m\n\u001b[1;32m    116\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model512\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1599\u001b[0m, in \u001b[0;36m_make_class_weight_map_fn\u001b[0;34m(class_weight)\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_class_weight_map_fn\u001b[39m(class_weight):\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies class weighting to a `Dataset`.\u001b[39;00m\n\u001b[1;32m   1587\u001b[0m \n\u001b[1;32m   1588\u001b[0m \u001b[38;5;124;03m    The `Dataset` is assumed to be in format `(x, y)` or `(x, y, sw)`, where\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;124;03m      weighting.\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1599\u001b[0m     class_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m()))\n\u001b[1;32m   1600\u001b[0m     expected_class_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(class_ids)))\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m class_ids \u001b[38;5;241m!=\u001b[39m expected_class_ids:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import (\n",
    "#     Conv2D,\n",
    "#     MaxPooling2D,\n",
    "#     Flatten,\n",
    "#     Dense,\n",
    "#     BatchNormalization,\n",
    "#     ZeroPadding2D,\n",
    "#     Activation,\n",
    "#     Dropout,\n",
    "# )\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# # Create the Sequential model\n",
    "# model512 = Sequential()\n",
    "\n",
    "# # Input Layer (Zero Padding)\n",
    "# model512.add(ZeroPadding2D(padding=(2, 2), input_shape=(512, 512, 3)))\n",
    "\n",
    "# # Layer 1\n",
    "# model512.add(Conv2D(32, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 2\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 3\n",
    "# model512.add(Conv2D(64, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 4\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 5\n",
    "# model512.add(Conv2D(96, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 6\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 7\n",
    "# model512.add(Conv2D(96, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 8\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 9\n",
    "# model512.add(Conv2D(128, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 10\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 11\n",
    "# model512.add(Conv2D(200, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 12\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 13 (Dropout)\n",
    "# model512.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 14\n",
    "# model512.add(Dense(1000))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "# model512.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 15\n",
    "# model512.add(Dense(500))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "# model512.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 16 (Output Layer)\n",
    "# model512.add(Dense(5, activation=\"softmax\"))  # Assuming 5 classes for classification\n",
    "\n",
    "# # Define the optimizer with specified learning rate and momentum\n",
    "# learning_rate = 1e-1\n",
    "# optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "# # Compile the model with SGD optimizer and specified loss function\n",
    "# model512.compile(\n",
    "#     optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "\n",
    "# # Define the learning rate schedule\n",
    "# def lr_schedule(epoch):\n",
    "#     return learning_rate * math.pow(0.5, math.floor((1 + epoch) / 10))\n",
    "\n",
    "\n",
    "# # Define the learning rate scheduler\n",
    "# lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# # Fit the model to the training data\n",
    "# history = model512.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=10,  # Assuming 10 epochs for training\n",
    "#     batch_size=16,  # Assuming batch size of 32\n",
    "#     callbacks=[lr_scheduler],  # Learning rate scheduler callback\n",
    "#     class_weight=\"auto\",  # Auto compute class weights\n",
    "#     verbose=1,\n",
    "# )  # Show training progress\n",
    "\n",
    "# # Evaluate the model on the test data\n",
    "# test_loss, test_accuracy = model512.evaluate(X_test, y_test)\n",
    "\n",
    "# print(f\"Test Loss: {test_loss}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# # base learning rate\n",
    "# base_learning_rate = 1e-4\n",
    "# # maximum learning rate\n",
    "# max_learning_rate = 1e-2\n",
    "\n",
    "# # Create an instance of SGD optimizer with initial learning rate\n",
    "# optimizer = SGD(learning_rate=base_learning_rate, momentum=0.9, clipnorm=1.0)\n",
    "\n",
    "# # create class weight\n",
    "# classes = np.unique(y_train)\n",
    "# class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
    "# class_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "\n",
    "# # create triangular schedule\n",
    "# def triangular_schedule(epoch):\n",
    "#     \"\"\"Triangular learning rate scheduler.\"\"\"\n",
    "#     cycle_length = 10  # Define the length of a cycle\n",
    "#     cycle = math.floor(1 + epoch / (2 * cycle_length))\n",
    "#     x = abs(epoch / cycle_length - 2 * cycle + 1)\n",
    "#     lr = base_learning_rate + (max_learning_rate - base_learning_rate) * max(0, (1 - x))\n",
    "#     return lr\n",
    "\n",
    "\n",
    "# # When fitting the model, include the learning rate scheduler callback\n",
    "# lr_scheduler = LearningRateScheduler(triangular_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the top layer of the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 01:26:42.931320: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7879262208 exceeds 10% of free system memory.\n",
      "2024-04-13 01:26:47.177854: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7879262208 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 01:26:52.265105: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8902\n",
      "2024-04-13 01:26:52.381890: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-13 01:26:53.061359: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-13 01:26:53.061428: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 39s 115ms/step - loss: 1.8181 - accuracy: 0.2720 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.5985 - accuracy: 0.3644 - lr: 0.0011\n",
      "Epoch 3/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.4761 - accuracy: 0.4182 - lr: 0.0021\n",
      "Epoch 4/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.3889 - accuracy: 0.4297 - lr: 0.0031\n",
      "Epoch 5/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.3507 - accuracy: 0.4772 - lr: 0.0041\n",
      "Epoch 6/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.2664 - accuracy: 0.4996 - lr: 0.0050\n",
      "Epoch 7/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.1420 - accuracy: 0.5217 - lr: 0.0060\n",
      "Epoch 8/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.0190 - accuracy: 0.5637 - lr: 0.0070\n",
      "Epoch 9/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.8811 - accuracy: 0.5980 - lr: 0.0080\n",
      "Epoch 10/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.7290 - accuracy: 0.6512 - lr: 0.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b785b7340>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compile(\n",
    "#     optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "# print(\"Fitting the top layer of the model\")\n",
    "# model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=10,\n",
    "#     batch_size=32,\n",
    "#     class_weight=class_weight_dict,\n",
    "#     callbacks=[lr_scheduler],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 34ms/step - loss: 1.3069 - accuracy: 0.4674\n",
      "Test Accuracy: 0.46743908524513245\n"
     ]
    }
   ],
   "source": [
    "# # Evaluate the model\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "# print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
