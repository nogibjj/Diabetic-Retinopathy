{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the zipped image files and convert them all to a standard size.\n",
    "once converted, they are stored in the relevant folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations\n",
    "modify the below configurations to suit your needs, beyond this, the rest of the code should work as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting default configuration options\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "desired_size = (512, 512)  # Modify this if required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the Path to the folders as per your system in case running this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repo Paths, No need to change these as they are present in the repo and are relative paths\n",
    "path_combine = \"../02_Data/Extra/messidor_combine.parquet\"  # path to the combined excel DF (present in repo)\n",
    "path_mapping = \"../02_Data/01_messidor_mapping.parquet\"  # path to the mapping parquet file (present in repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute Paths, Change these to the paths in your system\n",
    "path_source = \"/Users/revanth/Downloads/Messidor/\"  # path to the source folder (Regular Folder not Zip)\n",
    "path_dest = \"/Users/revanth/Documents/Messidor_Data/\"  # path to the destination folder (Regular Folder not Zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to change the below code beyond this point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Mapping File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Department</th>\n",
       "      <th>Retinopathy_Grade</th>\n",
       "      <th>Risk_of_Macular_Edema</th>\n",
       "      <th>Data_Source</th>\n",
       "      <th>Include</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>20051021_57798_0100_PP.tif</td>\n",
       "      <td>Service Ophtalmologie Lariboisière</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>20060411_61196_0200_PP.tif</td>\n",
       "      <td>CHU de St Etienne</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>20051021_58316_0100_PP.tif</td>\n",
       "      <td>Service Ophtalmologie Lariboisière</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>20051202_54498_0400_PP.tif</td>\n",
       "      <td>LaTIM - CHU de BREST</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>20051205_35110_0400_PP.tif</td>\n",
       "      <td>LaTIM - CHU de BREST</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Image_ID                          Department  \\\n",
       "293   20051021_57798_0100_PP.tif  Service Ophtalmologie Lariboisière   \n",
       "754   20060411_61196_0200_PP.tif                   CHU de St Etienne   \n",
       "320   20051021_58316_0100_PP.tif  Service Ophtalmologie Lariboisière   \n",
       "1190  20051202_54498_0400_PP.tif                LaTIM - CHU de BREST   \n",
       "341   20051205_35110_0400_PP.tif                LaTIM - CHU de BREST   \n",
       "\n",
       "      Retinopathy_Grade  Risk_of_Macular_Edema Data_Source  Include  Split  \n",
       "293                   0                      0    Messidor     True  Train  \n",
       "754                   3                      1    Messidor     True  Train  \n",
       "320                   0                      0    Messidor     True  Train  \n",
       "1190                  2                      2    Messidor     True  Train  \n",
       "341                   3                      0    Messidor    False  Train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Combined Mapping File\n",
    "labels = pd.read_parquet(path_combine)\n",
    "labels.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding empty column to store the original image size\n",
    "labels[\"Original_Size\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Annotation_Base33.xls',\n",
       " 'Annotation_Base32.xls',\n",
       " 'Annotation_Base24.xls',\n",
       " 'Annotation_Base31.xls',\n",
       " 'Annotation_Base21.xls',\n",
       " '.DS_Store',\n",
       " 'Annotation_Base34.xls',\n",
       " 'Annotation_Base22.xls',\n",
       " 'Annotation_Base23.xls',\n",
       " 'Base11.zip',\n",
       " 'Base12.zip',\n",
       " 'Base13.zip',\n",
       " 'Base14.zip',\n",
       " 'Base24.zip',\n",
       " 'Base31.zip',\n",
       " 'resize_samples',\n",
       " 'Base33.zip',\n",
       " 'Base32.zip',\n",
       " 'Base22.zip',\n",
       " 'Base23.zip',\n",
       " 'Base21.zip',\n",
       " 'Base34.zip',\n",
       " 'Annotation_Base12.xls',\n",
       " 'Annotation_Base13.xls',\n",
       " 'Annotation_Base11.xls',\n",
       " 'Annotation_Base14.xls']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lsiting all the files in the path_source folder\n",
    "files = os.listdir(path_source)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Base11.zip',\n",
       " 'Base12.zip',\n",
       " 'Base13.zip',\n",
       " 'Base14.zip',\n",
       " 'Base21.zip',\n",
       " 'Base22.zip',\n",
       " 'Base23.zip',\n",
       " 'Base24.zip',\n",
       " 'Base31.zip',\n",
       " 'Base32.zip',\n",
       " 'Base33.zip',\n",
       " 'Base34.zip']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering for only zip files\n",
    "zip_files = [\n",
    "    file for file in files if file.startswith(\"Base\") and file.endswith(\".zip\")\n",
    "]\n",
    "zip_files.sort()\n",
    "zip_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should have 12 zip files\n",
    "assert len(zip_files) == 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a temporary directory to extract the files\n",
    "\n",
    "# delete the temp directory if it already exists\n",
    "if os.path.exists(path_source + \"temp_dir/\"):\n",
    "    os.system(\"rm -rf \" + path_source + \"temp_dir/\")\n",
    "os.mkdir(path_source + \"temp_dir/\")\n",
    "temp_dir = path_source + \"temp_dir/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files from Base11.zip extracted successfully\n",
      "Files from Base12.zip extracted successfully\n",
      "Files from Base13.zip extracted successfully\n",
      "Files from Base14.zip extracted successfully\n",
      "Files from Base21.zip extracted successfully\n",
      "Files from Base22.zip extracted successfully\n",
      "Files from Base23.zip extracted successfully\n",
      "Files from Base24.zip extracted successfully\n",
      "Files from Base31.zip extracted successfully\n",
      "Files from Base32.zip extracted successfully\n",
      "Files from Base33.zip extracted successfully\n",
      "Files from Base34.zip extracted successfully\n"
     ]
    }
   ],
   "source": [
    "# extracting the contents of the zip files to the temporary directory\n",
    "for file in zip_files:\n",
    "    with zipfile.ZipFile(path_source + file, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(temp_dir)\n",
    "        print(f\"Files from {file} extracted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if temp_dir has sub-folders, extract the contents of the subfolders to the temp_dir\n",
    "\n",
    "# traverse root directory, and list directories as dirs and files as files\n",
    "for root, dirs, files in os.walk(temp_dir):\n",
    "    path = root.split(os.sep)\n",
    "\n",
    "    for file in files:\n",
    "        if not os.path.isdir(file):\n",
    "\n",
    "            # move file from nested folder into the base folder\n",
    "            shutil.move(os.path.join(root, file), os.path.join(temp_dir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(temp_dir):\n",
    "    # Deleting the sub-folders\n",
    "    for dir in dirs:\n",
    "        shutil.rmtree(os.path.join(root, dir))\n",
    "\n",
    "    # deleting all the excel files and DS_Store files\n",
    "    for file in files:\n",
    "        if file.endswith(\".xls\"):\n",
    "            os.remove(os.path.join(root, file))\n",
    "        if file == \".DS_Store\":\n",
    "            os.remove(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Base Images: 0\n",
      "Number of Non-Base Images: 1200\n"
     ]
    }
   ],
   "source": [
    "# check if all the files are loaded with the correct names\n",
    "num_base = 0\n",
    "unique_start = set()\n",
    "num_non_base = 0\n",
    "\n",
    "for name in os.listdir(temp_dir):\n",
    "    if \"Base\" in name:\n",
    "        num_base += 1\n",
    "        unique_start.add(name.split(\"/\")[0])\n",
    "    else:\n",
    "        num_non_base += 1\n",
    "    if name not in labels[\"Image_ID\"].values:\n",
    "        print(f\"Image {name} not found in the labels\")\n",
    "\n",
    "print(f\"Number of Base Images: {num_base}\")\n",
    "print(f\"Number of Non-Base Images: {num_non_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should have 1200 non-base images and 0 base images\n",
    "assert num_base == 0\n",
    "assert num_non_base == 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view images which are loaded with the incorrect names\n",
    "unique_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination folder already exists\n",
      "Existing Resized folder deleted successfully\n",
      "Existing Raw folder deleted successfully\n",
      "Train and Test folders created successfully in Resized folder\n",
      "Train and Test folders created successfully in Raw folder\n"
     ]
    }
   ],
   "source": [
    "# check if the target folder exists, if not create it\n",
    "if not os.path.exists(path_dest):\n",
    "    os.mkdir(path_dest)\n",
    "    print(\"Destination folder created successfully\")\n",
    "else:\n",
    "    print(\"Destination folder already exists\")\n",
    "\n",
    "# Deleting the exisiting files in the destination folder if any\n",
    "if os.path.exists(path_dest + \"Resized/\"):\n",
    "    os.system(\"rm -rf \" + path_dest + \"Resized/\")\n",
    "    print(\"Existing Resized folder deleted successfully\")\n",
    "os.mkdir(path_dest + \"Resized/\")\n",
    "\n",
    "\n",
    "# Deleting the exisiting files in the destination folder if any\n",
    "if os.path.exists(path_dest + \"Raw/\"):\n",
    "    os.system(\"rm -rf \" + path_dest + \"Raw/\")\n",
    "    print(\"Existing Raw folder deleted successfully\")\n",
    "os.mkdir(path_dest + \"Raw/\")\n",
    "\n",
    "# creating sub-folders for Train and Test\n",
    "os.mkdir(path_dest + \"Resized/\" + \"Train/\")\n",
    "os.mkdir(path_dest + \"Resized/\" + \"Test/\")\n",
    "print(\"Train and Test folders created successfully in Resized folder\")\n",
    "\n",
    "# creating sub-folders for Train and Test in Raw folder\n",
    "os.mkdir(path_dest + \"Raw/\" + \"Train/\")\n",
    "os.mkdir(path_dest + \"Raw/\" + \"Test/\")\n",
    "print(\"Train and Test folders created successfully in Raw folder\")\n",
    "\n",
    "path_train_resized = path_dest + \"Resized/\" + \"Train/\"\n",
    "path_test_resized = path_dest + \"Resized/\" + \"Test/\"\n",
    "path_train_raw = path_dest + \"Raw/\" + \"Train/\"\n",
    "path_test_raw = path_dest + \"Raw/\" + \"Test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100 images\n",
      "processed 200 images\n",
      "processed 300 images\n",
      "processed 400 images\n",
      "processed 500 images\n",
      "processed 600 images\n",
      "processed 700 images\n",
      "processed 800 images\n",
      "processed 900 images\n",
      "processed 1000 images\n",
      "processed 1100 images\n",
      "Processed 1187 images with 0 errors\n"
     ]
    }
   ],
   "source": [
    "# go through the temp_dir and process the images and save them in the target directory\n",
    "nums = 0  # to keep track of the number of images processed\n",
    "err_num = 0  # to keep track of the number of images that caused an error\n",
    "\n",
    "path = temp_dir\n",
    "for files in os.listdir(path):\n",
    "    if files.endswith(\".tif\"):\n",
    "        img = Image.open(path + files)\n",
    "        img_split = None  # so store if the image is test or train\n",
    "        try:\n",
    "            # add original size to the labels dataframe\n",
    "            idx = labels[labels[\"Image_ID\"] == files].index[0]\n",
    "            labels.at[idx, \"Original_Size\"] = img.size\n",
    "\n",
    "            # if the image is not marked as iclude, skip it\n",
    "            if labels.at[idx, \"Include\"] == 0:\n",
    "                continue\n",
    "            # get the split of the image\n",
    "            img_split = labels.at[idx, \"Split\"]\n",
    "\n",
    "            # save the raw image in the respective folder\n",
    "            if img_split == \"Train\":\n",
    "                img.save(path_train_raw + files)\n",
    "            elif img_split == \"Test\":\n",
    "                img.save(path_test_raw + files)\n",
    "\n",
    "            # resize the image\n",
    "            img = img.resize(desired_size)\n",
    "\n",
    "            # save the image\n",
    "            if img_split == \"Train\":\n",
    "                img.save(path_train_resized + files)\n",
    "            elif img_split == \"Test\":\n",
    "                img.save(path_test_resized + files)\n",
    "\n",
    "            nums += 1\n",
    "\n",
    "        except:\n",
    "            print(f\"Error processing {files}\")\n",
    "            err_num += 1\n",
    "            if err_num > 10:\n",
    "                # breaking so that we can fix the error before trying more images\n",
    "                print(\"Too many errors!, breaking\")\n",
    "                break\n",
    "            continue\n",
    "    if nums % 100 == 0:\n",
    "        print(f\"processed {nums} images\")\n",
    "print(f\"Processed {nums} images with {err_num} errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should have 1200 images\n",
    "assert nums == labels[\"Include\"].sum()\n",
    "\n",
    "# We should have 0 errors\n",
    "assert err_num == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train folder should have same number of images as the Train split\n",
    "assert len(os.listdir(path_train_resized)) == len(\n",
    "    labels[(labels[\"Split\"] == \"Train\") & labels[\"Include\"]]\n",
    ")\n",
    "assert len(os.listdir(path_train_raw)) == len(\n",
    "    labels[(labels[\"Split\"] == \"Train\") & labels[\"Include\"]]\n",
    ")\n",
    "\n",
    "# Test folder should have same number of images as the Test split\n",
    "assert len(os.listdir(path_test_resized)) == len(\n",
    "    labels[(labels[\"Split\"] == \"Test\") & labels[\"Include\"]]\n",
    ")\n",
    "assert len(os.listdir(path_test_raw)) == len(\n",
    "    labels[(labels[\"Split\"] == \"Test\") & labels[\"Include\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Department</th>\n",
       "      <th>Retinopathy_Grade</th>\n",
       "      <th>Risk_of_Macular_Edema</th>\n",
       "      <th>Data_Source</th>\n",
       "      <th>Include</th>\n",
       "      <th>Split</th>\n",
       "      <th>Original_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>20060411_61478_0200_PP.tif</td>\n",
       "      <td>CHU de St Etienne</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "      <td>(1440, 960)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>20051202_55484_0400_PP.tif</td>\n",
       "      <td>LaTIM - CHU de BREST</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "      <td>(1440, 960)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>20051020_64703_0100_PP.tif</td>\n",
       "      <td>Service Ophtalmologie Lariboisière</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "      <td>(2240, 1488)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>20051214_56392_0100_PP.tif</td>\n",
       "      <td>Service Ophtalmologie Lariboisière</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "      <td>(2240, 1488)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>20060410_47351_0200_PP.tif</td>\n",
       "      <td>CHU de St Etienne</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Messidor</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "      <td>(1440, 960)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Image_ID                          Department  \\\n",
       "759   20060411_61478_0200_PP.tif                   CHU de St Etienne   \n",
       "841   20051202_55484_0400_PP.tif                LaTIM - CHU de BREST   \n",
       "1092  20051020_64703_0100_PP.tif  Service Ophtalmologie Lariboisière   \n",
       "56    20051214_56392_0100_PP.tif  Service Ophtalmologie Lariboisière   \n",
       "829   20060410_47351_0200_PP.tif                   CHU de St Etienne   \n",
       "\n",
       "      Retinopathy_Grade  Risk_of_Macular_Edema Data_Source  Include  Split  \\\n",
       "759                   3                      1    Messidor     True  Train   \n",
       "841                   2                      0    Messidor     True  Train   \n",
       "1092                  0                      0    Messidor     True  Train   \n",
       "56                    0                      0    Messidor     True  Train   \n",
       "829                   2                      0    Messidor     True  Train   \n",
       "\n",
       "     Original_Size  \n",
       "759    (1440, 960)  \n",
       "841    (1440, 960)  \n",
       "1092  (2240, 1488)  \n",
       "56    (2240, 1488)  \n",
       "829    (1440, 960)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the labels dataframe\n",
    "labels.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the labels dataframe as a parquet file\n",
    "labels.to_parquet(path_mapping, index=False)\n",
    "\n",
    "# saving labels df as excel and parquet in both sub-folders\n",
    "labels.to_parquet(path_dest + \"/Raw/\" + \"messidor_mapping.parquet\", index=False)\n",
    "labels.to_excel(path_dest + \"/Raw/\" + \"messidor_mapping.xlsx\", index=False)\n",
    "labels.to_parquet(path_dest + \"/Resized/\" + \"messidor_mapping.parquet\", index=False)\n",
    "labels.to_excel(path_dest + \"/Resized/\" + \"messidor_mapping.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up the temporary directory\n",
    "shutil.rmtree(temp_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
