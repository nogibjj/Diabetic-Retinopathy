{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 20:10:56.204630: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 20:10:56.360986: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-13 20:10:57.156975: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-13 20:10:57.157163: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-13 20:10:57.157184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variable for TensorFlow\n",
    "# os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configure GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth before initializing GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Handle potential errors here\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"../../aws_s3/DDR+APTOS_TRAIN_TEST/train_test_DDR_APTOS.csv\")\n",
    "\n",
    "filtered_data = data[data[\"Data_source\"] == \"DDR\"]\n",
    "# Split the dataset into training and testing sets\n",
    "train_data = filtered_data[filtered_data[\"Split\"] == \"Train\"]\n",
    "test_data = filtered_data[filtered_data[\"Split\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directories\n",
    "luminosity_output_dir_train = \"luminosity_images_train/\"\n",
    "cropped_output_dir_train = \"cropped_images_train/\"\n",
    "normalized_output_dir_train = \"normalized_images_train/\"\n",
    "luminosity_output_dir_test = \"luminosity_images_test/\"\n",
    "cropped_output_dir_test = \"cropped_images_test/\"\n",
    "normalized_output_dir_test = \"normalized_images_test/\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(luminosity_output_dir_train, exist_ok=True)\n",
    "os.makedirs(cropped_output_dir_train, exist_ok=True)\n",
    "os.makedirs(normalized_output_dir_train, exist_ok=True)\n",
    "os.makedirs(luminosity_output_dir_test, exist_ok=True)\n",
    "os.makedirs(cropped_output_dir_test, exist_ok=True)\n",
    "os.makedirs(normalized_output_dir_test, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def luminosity_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
    "    l_eq = clahe.apply(l)\n",
    "\n",
    "    # Merge back LAB channels\n",
    "    lab_eq = cv2.merge((l_eq, a, b))\n",
    "    enhanced_image = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Image noise removal using Gaussian filter\n",
    "    filtered_image = cv2.GaussianBlur(enhanced_image, (5, 5), 0)\n",
    "\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, threshold=20, resize_flag=False, desired_size=(512, 512)):\n",
    "    img_np = np.array(img)\n",
    "    x_dim = img_np.shape[0]\n",
    "    y_dim = img_np.shape[1]\n",
    "    pixel_sums = img_np.sum(axis=2)\n",
    "    x_arr = pixel_sums.sum(axis=1)\n",
    "    y_arr = pixel_sums.sum(axis=0)\n",
    "    x_start = np.where(x_arr > threshold * y_dim)[0][0]\n",
    "    x_end = np.where(x_arr > threshold * y_dim)[0][-1]\n",
    "    y_start = np.where(y_arr > threshold * x_dim)[0][0]\n",
    "    y_end = np.where(y_arr > threshold * x_dim)[0][-1]\n",
    "    new_img = img_np[x_start:x_end, y_start:y_end]\n",
    "    new_img = Image.fromarray(new_img)\n",
    "    if resize_flag:\n",
    "        new_img = new_img.resize(desired_size)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(img):\n",
    "    # Convert image to numpy array\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Calculate mean and standard deviation (std) channel-wise\n",
    "    mean_channels = np.mean(img_np, axis=(0, 1))\n",
    "    std_channels = np.std(img_np, axis=(0, 1))\n",
    "\n",
    "    # Normalize each channel separately\n",
    "    normalized_image = np.zeros_like(img_np, dtype=np.float32)\n",
    "    for channel in range(img_np.shape[2]):\n",
    "        normalized_image[:, :, channel] = (\n",
    "            img_np[:, :, channel] - mean_channels[channel]\n",
    "        ) / std_channels[channel]\n",
    "\n",
    "    # Scale values to be within [0, 255]\n",
    "    normalized_image = (\n",
    "        (normalized_image - np.min(normalized_image))\n",
    "        / (np.max(normalized_image) - np.min(normalized_image))\n",
    "        * 255\n",
    "    )\n",
    "\n",
    "    # Clip and return the normalized image\n",
    "    normalized_image = np.clip(normalized_image, 0, 255)\n",
    "    return normalized_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 34 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 35 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 38 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "\n",
    "# Function to get the correct image path with extension\n",
    "def get_image_path(base_dir, img_name):\n",
    "    for ext in [\"jpg\", \"png\"]:\n",
    "        if \"jpg\" in img_name or \"png\" in img_name:\n",
    "            temp_path = f\"{base_dir}/{img_name}\"\n",
    "        else:\n",
    "            temp_path = f\"{base_dir}/{img_name}.{ext}\"\n",
    "        if os.path.exists(temp_path):\n",
    "            return temp_path\n",
    "    return None  # Return None if no file is found\n",
    "\n",
    "\n",
    "# Load and preprocess each image\n",
    "for index, row in train_data.iterrows():\n",
    "    img_name, label = row[\"Image_ID\"], row[\"Retinopathy_Grade\"]\n",
    "    image_path = get_image_path(\n",
    "        \"../../aws_s3/DDR+APTOS_TRAIN_TEST/train_new\", img_name\n",
    "    )  # Dynamically get the correct image path\n",
    "\n",
    "    if image_path is None:\n",
    "        print(f\"Image file for {img_name} not found in JPG or PNG format.\")\n",
    "        continue  # Skip this iteration if the file doesn't exist\n",
    "\n",
    "    # Change Luminosity and do noise removal for the image\n",
    "    filtered_image = luminosity_image(image_path)\n",
    "\n",
    "    # Crop and resize the image\n",
    "    luminosity_img = Image.fromarray(filtered_image)\n",
    "    cropped_resized_img = crop_image(\n",
    "        luminosity_img, resize_flag=True, desired_size=(512, 512)\n",
    "    )\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save cropped image\n",
    "    # if \"jpg\" in img_name:\n",
    "    #     cropped_img_name = f\"{img_name}_{index+1}.jpg\"\n",
    "    # elif \"png\" in img_name:\n",
    "    #     cropped_img_name = f\"{img_name}_{index+1}.png\"\n",
    "    # cropped_img_name = f\"{img_name}\"\n",
    "    # cropped_img_path = os.path.join(cropped_output_dir_train, cropped_img_name)\n",
    "    # cropped_resized_img.save(cropped_img_path)\n",
    "\n",
    "    # Normalize the image\n",
    "    # normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save normalized image\n",
    "    # if \"jpg\" in img_name:\n",
    "    #     normalized_img_name = f\"norm_{img_name}_{index+1}.jpg\"\n",
    "    # elif \"png\" in img_name:\n",
    "    #     normalized_img_name = f\"norm_{img_name}_{index+1}.png\"\n",
    "    normalized_img_name = f\"norm_{img_name}\"\n",
    "    normalized_img_path = os.path.join(normalized_output_dir_train, normalized_img_name)\n",
    "    cv2.imwrite(normalized_img_path, cv2.cvtColor(normalized_img, cv2.COLOR_RGB2BGR))\n",
    "    X_train.append(normalized_img)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for index, row in test_data.iterrows():\n",
    "    img_name, label = row[\"Image_ID\"], row[\"Retinopathy_Grade\"]\n",
    "    image_path = get_image_path(\n",
    "        \"../../aws_s3/DDR+APTOS_TRAIN_TEST/test_new\", img_name\n",
    "    )  # Dynamically get the correct image path\n",
    "\n",
    "    if image_path is None:\n",
    "        print(f\"Image file for {img_name} not found in JPG or PNG format.\")\n",
    "        continue  # Skip this iteration if the file doesn't exist\n",
    "\n",
    "    # Change Luminosity and do noise removal for the image\n",
    "    filtered_image = luminosity_image(image_path)\n",
    "\n",
    "    # Crop and resize the image\n",
    "    luminosity_img = Image.fromarray(filtered_image)\n",
    "    cropped_resized_img = crop_image(\n",
    "        luminosity_img, resize_flag=True, desired_size=(512, 512)\n",
    "    )\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_img = normalize_image(cropped_resized_img)\n",
    "\n",
    "    # Save normalized image\n",
    "    normalized_img_name = f\"norm_{img_name}\"\n",
    "    normalized_img_path = os.path.join(normalized_output_dir_test, normalized_img_name)\n",
    "    cv2.imwrite(normalized_img_path, cv2.cvtColor(normalized_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Append to X_test and y_test\n",
    "    X_test.append(normalized_img)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 16, 16, 512)       14714688  \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               67109376  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,826,629\n",
      "Trainable params: 67,111,941\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 21:00:37.971381: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.87GiB (rounded to 6303252480)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-04-13 21:00:37.971452: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2024-04-13 21:00:37.971471: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 66, Chunks in use: 66. 16.5KiB allocated for chunks. 16.5KiB in use in bin. 2.4KiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971482: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 8, Chunks in use: 8. 4.8KiB allocated for chunks. 4.8KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971492: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 13, Chunks in use: 13. 14.2KiB allocated for chunks. 14.2KiB in use in bin. 13.0KiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971502: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 30, Chunks in use: 30. 63.5KiB allocated for chunks. 63.5KiB in use in bin. 60.0KiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971512: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 4, Chunks in use: 4. 27.0KiB allocated for chunks. 27.0KiB in use in bin. 27.0KiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971522: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 7, Chunks in use: 6. 74.2KiB allocated for chunks. 65.8KiB in use in bin. 65.7KiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971531: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 2, Chunks in use: 1. 38.0KiB allocated for chunks. 18.0KiB in use in bin. 10.0KiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971541: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 62.8KiB allocated for chunks. 62.8KiB in use in bin. 62.6KiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971551: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971562: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971572: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 7, Chunks in use: 7. 2.51MiB allocated for chunks. 2.51MiB in use in bin. 1.55MiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971581: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 5, Chunks in use: 4. 3.18MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971590: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 5, Chunks in use: 3. 7.42MiB allocated for chunks. 4.89MiB in use in bin. 3.38MiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971601: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 9, Chunks in use: 9. 20.65MiB allocated for chunks. 20.65MiB in use in bin. 19.12MiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971610: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 4, Chunks in use: 4. 18.00MiB allocated for chunks. 18.00MiB in use in bin. 18.00MiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971620: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 20, Chunks in use: 20. 184.50MiB allocated for chunks. 184.50MiB in use in bin. 180.00MiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971629: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971638: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971651: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971661: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 204.25MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971671: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 11, Chunks in use: 8. 14.01GiB allocated for chunks. 8.89GiB in use in bin. 8.84GiB client-requested in use in bin.\n",
      "2024-04-13 21:00:37.971680: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 5.87GiB was 256.00MiB, Chunk State: \n",
      "2024-04-13 21:00:37.971698: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 256.00MiB | Requested Size: 256.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 256.00MiB | Requested Size: 256.00MiB | in_use: 1 | bin_num: -1, next:   Size: 314.25MiB | Requested Size: 256.00MiB | in_use: 1 | bin_num: -1\n",
      "2024-04-13 21:00:37.971711: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 462.50MiB | Requested Size: 256.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 9.00MiB | Requested Size: 9.00MiB | in_use: 1 | bin_num: -1, next:   Size: 256.00MiB | Requested Size: 256.00MiB | in_use: 1 | bin_num: -1\n",
      "2024-04-13 21:00:37.971722: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 4.42GiB | Requested Size: 9.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 9.00MiB | Requested Size: 9.00MiB | in_use: 1 | bin_num: -1\n",
      "2024-04-13 21:00:37.971730: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 15509553152\n",
      "2024-04-13 21:00:37.971761: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000000 of size 1280 next 1\n",
      "2024-04-13 21:00:37.971774: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000500 of size 256 next 2\n",
      "2024-04-13 21:00:37.971783: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000600 of size 256 next 3\n",
      "2024-04-13 21:00:37.971792: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000700 of size 256 next 5\n",
      "2024-04-13 21:00:37.971800: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000800 of size 256 next 6\n",
      "2024-04-13 21:00:37.971808: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000900 of size 256 next 4\n",
      "2024-04-13 21:00:37.971817: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000a00 of size 256 next 7\n",
      "2024-04-13 21:00:37.971825: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000b00 of size 256 next 12\n",
      "2024-04-13 21:00:37.971833: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000c00 of size 256 next 10\n",
      "2024-04-13 21:00:37.971842: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000d00 of size 256 next 11\n",
      "2024-04-13 21:00:37.971850: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca000e00 of size 512 next 15\n",
      "2024-04-13 21:00:37.971859: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001000 of size 256 next 16\n",
      "2024-04-13 21:00:37.971867: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001100 of size 256 next 19\n",
      "2024-04-13 21:00:37.971876: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001200 of size 256 next 50\n",
      "2024-04-13 21:00:37.971884: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001300 of size 256 next 22\n",
      "2024-04-13 21:00:37.971892: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001400 of size 256 next 20\n",
      "2024-04-13 21:00:37.971901: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001500 of size 256 next 21\n",
      "2024-04-13 21:00:37.971911: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001600 of size 1024 next 25\n",
      "2024-04-13 21:00:37.971920: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001a00 of size 256 next 26\n",
      "2024-04-13 21:00:37.971929: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001b00 of size 256 next 29\n",
      "2024-04-13 21:00:37.971937: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca001c00 of size 1024 next 32\n",
      "2024-04-13 21:00:37.971945: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca002000 of size 256 next 53\n",
      "2024-04-13 21:00:37.971954: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca002100 of size 256 next 58\n",
      "2024-04-13 21:00:37.971962: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca002200 of size 256 next 56\n",
      "2024-04-13 21:00:37.971970: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca002300 of size 256 next 35\n",
      "2024-04-13 21:00:37.971978: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca002400 of size 256 next 30\n",
      "2024-04-13 21:00:37.971987: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca002500 of size 256 next 31\n",
      "2024-04-13 21:00:37.971995: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca002600 of size 2048 next 37\n",
      "2024-04-13 21:00:37.972004: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca002e00 of size 256 next 38\n",
      "2024-04-13 21:00:37.972013: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca002f00 of size 256 next 41\n",
      "2024-04-13 21:00:37.972021: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca003000 of size 2048 next 44\n",
      "2024-04-13 21:00:37.972029: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca003800 of size 2048 next 8\n",
      "2024-04-13 21:00:37.972037: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca004000 of size 256 next 54\n",
      "2024-04-13 21:00:37.972046: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca004100 of size 512 next 17\n",
      "2024-04-13 21:00:37.972054: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca004300 of size 1024 next 28\n",
      "2024-04-13 21:00:37.972063: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca004700 of size 2048 next 39\n",
      "2024-04-13 21:00:37.972071: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca004f00 of size 2048 next 49\n",
      "2024-04-13 21:00:37.972079: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca005700 of size 2048 next 51\n",
      "2024-04-13 21:00:37.972088: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca005f00 of size 2048 next 48\n",
      "2024-04-13 21:00:37.972096: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca006700 of size 256 next 57\n",
      "2024-04-13 21:00:37.972105: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca006800 of size 256 next 63\n",
      "2024-04-13 21:00:37.972113: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca006900 of size 256 next 64\n",
      "2024-04-13 21:00:37.972121: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca006a00 of size 256 next 65\n",
      "2024-04-13 21:00:37.972130: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca006b00 of size 256 next 66\n",
      "2024-04-13 21:00:37.972138: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca006c00 of size 256 next 67\n",
      "2024-04-13 21:00:37.972146: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca006d00 of size 256 next 68\n",
      "2024-04-13 21:00:37.972155: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca006e00 of size 256 next 69\n",
      "2024-04-13 21:00:37.972163: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca006f00 of size 256 next 70\n",
      "2024-04-13 21:00:37.972171: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca007000 of size 256 next 71\n",
      "2024-04-13 21:00:37.972181: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca007100 of size 256 next 74\n",
      "2024-04-13 21:00:37.972190: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca007200 of size 256 next 52\n",
      "2024-04-13 21:00:37.972198: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca007300 of size 256 next 47\n",
      "2024-04-13 21:00:37.972206: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca007400 of size 6912 next 42\n",
      "2024-04-13 21:00:37.972215: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca008f00 of size 281600 next 14\n",
      "2024-04-13 21:00:37.972224: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca04db00 of size 442368 next 18\n",
      "2024-04-13 21:00:37.972232: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca0b9b00 of size 2064384 next 23\n",
      "2024-04-13 21:00:37.972241: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca2b1b00 of size 589824 next 13\n",
      "2024-04-13 21:00:37.972250: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca341b00 of size 4718592 next 33\n",
      "2024-04-13 21:00:37.972258: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7c1b00 of size 2048 next 73\n",
      "2024-04-13 21:00:37.972267: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7c2300 of size 18432 next 59\n",
      "2024-04-13 21:00:37.972275: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7c6b00 of size 10240 next 60\n",
      "2024-04-13 21:00:37.972284: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7c9300 of size 64256 next 62\n",
      "2024-04-13 21:00:37.972293: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7d8e00 of size 2048 next 75\n",
      "2024-04-13 21:00:37.972301: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7d9600 of size 10240 next 76\n",
      "2024-04-13 21:00:37.972310: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dbe00 of size 256 next 77\n",
      "2024-04-13 21:00:37.972318: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dbf00 of size 256 next 78\n",
      "2024-04-13 21:00:37.972327: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc000 of size 256 next 79\n",
      "2024-04-13 21:00:37.972335: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc100 of size 256 next 80\n",
      "2024-04-13 21:00:37.972343: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc200 of size 256 next 81\n",
      "2024-04-13 21:00:37.972352: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc300 of size 256 next 82\n",
      "2024-04-13 21:00:37.972360: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc400 of size 256 next 83\n",
      "2024-04-13 21:00:37.972368: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc500 of size 256 next 84\n",
      "2024-04-13 21:00:37.972377: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc600 of size 256 next 85\n",
      "2024-04-13 21:00:37.972385: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc700 of size 256 next 87\n",
      "2024-04-13 21:00:37.972393: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc800 of size 256 next 96\n",
      "2024-04-13 21:00:37.972402: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dc900 of size 256 next 95\n",
      "2024-04-13 21:00:37.972410: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dca00 of size 256 next 86\n",
      "2024-04-13 21:00:37.972419: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dcb00 of size 768 next 97\n",
      "2024-04-13 21:00:37.972428: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7dce00 of size 16128 next 98\n",
      "2024-04-13 21:00:37.972436: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e0d00 of size 2048 next 106\n",
      "2024-04-13 21:00:37.972445: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e1500 of size 6912 next 123\n",
      "2024-04-13 21:00:37.972455: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e3000 of size 256 next 103\n",
      "2024-04-13 21:00:37.972463: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e3100 of size 512 next 102\n",
      "2024-04-13 21:00:37.972471: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e3300 of size 1024 next 108\n",
      "2024-04-13 21:00:37.972480: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e3700 of size 1024 next 111\n",
      "2024-04-13 21:00:37.972488: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e3b00 of size 1024 next 110\n",
      "2024-04-13 21:00:37.972496: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e3f00 of size 2048 next 115\n",
      "2024-04-13 21:00:37.972505: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e4700 of size 2048 next 112\n",
      "2024-04-13 21:00:37.972513: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e4f00 of size 2048 next 121\n",
      "2024-04-13 21:00:37.972521: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e5700 of size 2048 next 100\n",
      "2024-04-13 21:00:37.972530: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e5f00 of size 2048 next 120\n",
      "2024-04-13 21:00:37.972538: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e6700 of size 2048 next 116\n",
      "2024-04-13 21:00:37.972546: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e6f00 of size 256 next 89\n",
      "2024-04-13 21:00:37.972555: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e7000 of size 256 next 101\n",
      "2024-04-13 21:00:37.972563: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e7100 of size 256 next 104\n",
      "2024-04-13 21:00:37.972571: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e7200 of size 2048 next 149\n",
      "2024-04-13 21:00:37.972579: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e7a00 of size 2048 next 143\n",
      "2024-04-13 21:00:37.972588: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e8200 of size 2048 next 153\n",
      "2024-04-13 21:00:37.972596: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e8a00 of size 2048 next 90\n",
      "2024-04-13 21:00:37.972605: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca7e9200 of size 449280 next 99\n",
      "2024-04-13 21:00:37.972614: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca856d00 of size 147456 next 91\n",
      "2024-04-13 21:00:37.972622: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ca87ad00 of size 2211840 next 88\n",
      "2024-04-13 21:00:37.972631: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0caa96d00 of size 589824 next 107\n",
      "2024-04-13 21:00:37.972639: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0cab26d00 of size 2928128 next 36\n",
      "2024-04-13 21:00:37.972648: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0cadf1b00 of size 2359296 next 27\n",
      "2024-04-13 21:00:37.972656: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0cb031b00 of size 2359296 next 40\n",
      "2024-04-13 21:00:37.972665: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0cb271b00 of size 9437184 next 34\n",
      "2024-04-13 21:00:37.972674: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0cbb71b00 of size 9437184 next 46\n",
      "2024-04-13 21:00:37.972682: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0cc471b00 of size 9437184 next 45\n",
      "2024-04-13 21:00:37.972690: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ccd71b00 of size 9437184 next 9\n",
      "2024-04-13 21:00:37.972698: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0cd671b00 of size 9437184 next 43\n",
      "2024-04-13 21:00:37.972707: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0cdf71b00 of size 268435456 next 72\n",
      "2024-04-13 21:00:37.972717: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0ddf71b00 of size 268435456 next 55\n",
      "2024-04-13 21:00:37.972725: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0edf71b00 of size 268435456 next 24\n",
      "2024-04-13 21:00:37.972734: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd0fdf71b00 of size 6303252480 next 61\n",
      "2024-04-13 21:00:37.972743: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd275ab1b00 of size 1576009728 next 92\n",
      "2024-04-13 21:00:37.972751: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d39b1b00 of size 9437184 next 122\n",
      "2024-04-13 21:00:37.972759: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d42b1b00 of size 9437184 next 124\n",
      "2024-04-13 21:00:37.972767: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d4bb1b00 of size 2359296 next 148\n",
      "2024-04-13 21:00:37.972776: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d4df1b00 of size 2359296 next 146\n",
      "2024-04-13 21:00:37.972784: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d5031b00 of size 2359296 next 145\n",
      "2024-04-13 21:00:37.972792: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd2d5271b00 of size 1179648 next 177\n",
      "2024-04-13 21:00:37.972801: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d5391b00 of size 1179648 next 125\n",
      "2024-04-13 21:00:37.972809: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d54b1b00 of size 9437184 next 117\n",
      "2024-04-13 21:00:37.972818: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d5db1b00 of size 4718592 next 138\n",
      "2024-04-13 21:00:37.972826: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d6231b00 of size 9437184 next 137\n",
      "2024-04-13 21:00:37.972835: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d6b31b00 of size 9437184 next 152\n",
      "2024-04-13 21:00:37.972843: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d7431b00 of size 9437184 next 147\n",
      "2024-04-13 21:00:37.972851: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d7d31b00 of size 9437184 next 154\n",
      "2024-04-13 21:00:37.972860: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2d8631b00 of size 9437184 next 156\n",
      "2024-04-13 21:00:37.972868: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd2d8f31b00 of size 484966400 next 94\n",
      "2024-04-13 21:00:37.972876: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd2f5db1b00 of size 268435456 next 105\n",
      "2024-04-13 21:00:37.972885: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd305db1b00 of size 2359296 next 179\n",
      "2024-04-13 21:00:37.972893: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd305ff1b00 of size 9437184 next 175\n",
      "2024-04-13 21:00:37.972901: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd3068f1b00 of size 9437184 next 184\n",
      "2024-04-13 21:00:37.972910: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd3071f1b00 of size 4718592 next 178\n",
      "2024-04-13 21:00:37.972918: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd307671b00 of size 9437184 next 182\n",
      "2024-04-13 21:00:37.972926: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd307f71b00 of size 9437184 next 188\n",
      "2024-04-13 21:00:37.972935: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd308871b00 of size 9437184 next 190\n",
      "2024-04-13 21:00:37.972943: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd309171b00 of size 214171648 next 133\n",
      "2024-04-13 21:00:37.972952: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd315db1b00 of size 268435456 next 140\n",
      "2024-04-13 21:00:37.972960: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd325db1b00 of size 268435456 next 165\n",
      "2024-04-13 21:00:37.972969: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd335db1b00 of size 329515008 next 113\n",
      "2024-04-13 21:00:37.972979: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd3497f1b00 of size 2359296 next 93\n",
      "2024-04-13 21:00:37.972987: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a31b00 of size 256 next 129\n",
      "2024-04-13 21:00:37.972996: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a31c00 of size 768 next 128\n",
      "2024-04-13 21:00:37.973004: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a31f00 of size 1536 next 130\n",
      "2024-04-13 21:00:37.973012: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a32500 of size 1024 next 144\n",
      "2024-04-13 21:00:37.973021: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a32900 of size 3584 next 131\n",
      "2024-04-13 21:00:37.973029: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a33700 of size 256 next 160\n",
      "2024-04-13 21:00:37.973037: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a33800 of size 512 next 135\n",
      "2024-04-13 21:00:37.973046: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a33a00 of size 1024 next 142\n",
      "2024-04-13 21:00:37.973054: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a33e00 of size 2048 next 151\n",
      "2024-04-13 21:00:37.973063: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a34600 of size 256 next 159\n",
      "2024-04-13 21:00:37.973071: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a34700 of size 256 next 150\n",
      "2024-04-13 21:00:37.973080: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a34800 of size 256 next 158\n",
      "2024-04-13 21:00:37.973088: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a34900 of size 2048 next 183\n",
      "2024-04-13 21:00:37.973096: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a35100 of size 2048 next 180\n",
      "2024-04-13 21:00:37.973104: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a35900 of size 2048 next 187\n",
      "2024-04-13 21:00:37.973113: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a36100 of size 2560 next 127\n",
      "2024-04-13 21:00:37.973121: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a36b00 of size 10240 next 126\n",
      "2024-04-13 21:00:37.973130: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a39300 of size 2048 next 155\n",
      "2024-04-13 21:00:37.973138: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a39b00 of size 6912 next 157\n",
      "2024-04-13 21:00:37.973147: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a3b600 of size 285952 next 134\n",
      "2024-04-13 21:00:37.973155: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349a81300 of size 442368 next 136\n",
      "2024-04-13 21:00:37.973164: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349aed300 of size 589824 next 174\n",
      "2024-04-13 21:00:37.973172: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd349b7d300 of size 1474560 next 139\n",
      "2024-04-13 21:00:37.973180: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349ce5300 of size 589824 next 132\n",
      "2024-04-13 21:00:37.973189: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d75300 of size 256 next 164\n",
      "2024-04-13 21:00:37.973197: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d75400 of size 768 next 163\n",
      "2024-04-13 21:00:37.973205: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d75700 of size 1536 next 176\n",
      "2024-04-13 21:00:37.973214: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d75d00 of size 1024 next 172\n",
      "2024-04-13 21:00:37.973226: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d76100 of size 3584 next 166\n",
      "2024-04-13 21:00:37.973235: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d76f00 of size 256 next 194\n",
      "2024-04-13 21:00:37.973245: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d77000 of size 512 next 170\n",
      "2024-04-13 21:00:37.973254: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d77200 of size 1024 next 173\n",
      "2024-04-13 21:00:37.973262: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d77600 of size 2048 next 185\n",
      "2024-04-13 21:00:37.973270: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d77e00 of size 256 next 193\n",
      "2024-04-13 21:00:37.973279: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d77f00 of size 256 next 186\n",
      "2024-04-13 21:00:37.973287: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d78000 of size 256 next 192\n",
      "2024-04-13 21:00:37.973295: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd349d78100 of size 8704 next 162\n",
      "2024-04-13 21:00:37.973304: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d7a300 of size 10240 next 161\n",
      "2024-04-13 21:00:37.973312: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d7cb00 of size 2048 next 189\n",
      "2024-04-13 21:00:37.973320: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d7d300 of size 6912 next 191\n",
      "2024-04-13 21:00:37.973329: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349d7ee00 of size 285952 next 169\n",
      "2024-04-13 21:00:37.973337: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349dc4b00 of size 442368 next 171\n",
      "2024-04-13 21:00:37.973346: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd349e30b00 of size 20480 next 167\n",
      "2024-04-13 21:00:37.973354: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349e35b00 of size 10240 next 181\n",
      "2024-04-13 21:00:37.973362: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd349e38300 of size 970752 next 141\n",
      "2024-04-13 21:00:37.973371: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd349f25300 of size 1886208 next 114\n",
      "2024-04-13 21:00:37.973380: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd34a0f1b00 of size 4718592 next 109\n",
      "2024-04-13 21:00:37.973388: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd34a571b00 of size 14155776 next 119\n",
      "2024-04-13 21:00:37.973397: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd34b2f1b00 of size 9437184 next 118\n",
      "2024-04-13 21:00:37.973405: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd34bbf1b00 of size 4742833408 next 18446744073709551615\n",
      "2024-04-13 21:00:37.973413: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2024-04-13 21:00:37.973423: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 66 Chunks of size 256 totalling 16.5KiB\n",
      "2024-04-13 21:00:37.973432: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 5 Chunks of size 512 totalling 2.5KiB\n",
      "2024-04-13 21:00:37.973441: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 768 totalling 2.2KiB\n",
      "2024-04-13 21:00:37.973449: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 10 Chunks of size 1024 totalling 10.0KiB\n",
      "2024-04-13 21:00:37.973457: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-04-13 21:00:37.973465: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 1536 totalling 3.0KiB\n",
      "2024-04-13 21:00:37.973473: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 27 Chunks of size 2048 totalling 54.0KiB\n",
      "2024-04-13 21:00:37.973482: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 2560 totalling 2.5KiB\n",
      "2024-04-13 21:00:37.973490: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 3584 totalling 7.0KiB\n",
      "2024-04-13 21:00:37.973498: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 6912 totalling 27.0KiB\n",
      "2024-04-13 21:00:37.973506: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 5 Chunks of size 10240 totalling 50.0KiB\n",
      "2024-04-13 21:00:37.973517: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 16128 totalling 15.8KiB\n",
      "2024-04-13 21:00:37.973525: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 18432 totalling 18.0KiB\n",
      "2024-04-13 21:00:37.973534: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 64256 totalling 62.8KiB\n",
      "2024-04-13 21:00:37.973542: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 147456 totalling 144.0KiB\n",
      "2024-04-13 21:00:37.973551: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 281600 totalling 275.0KiB\n",
      "2024-04-13 21:00:37.973559: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 285952 totalling 558.5KiB\n",
      "2024-04-13 21:00:37.973567: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 442368 totalling 1.27MiB\n",
      "2024-04-13 21:00:37.973576: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 449280 totalling 438.8KiB\n",
      "2024-04-13 21:00:37.973584: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 589824 totalling 2.25MiB\n",
      "2024-04-13 21:00:37.973592: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1179648 totalling 1.12MiB\n",
      "2024-04-13 21:00:37.973600: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1886208 totalling 1.80MiB\n",
      "2024-04-13 21:00:37.973609: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 2064384 totalling 1.97MiB\n",
      "2024-04-13 21:00:37.973617: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 2211840 totalling 2.11MiB\n",
      "2024-04-13 21:00:37.973625: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 7 Chunks of size 2359296 totalling 15.75MiB\n",
      "2024-04-13 21:00:37.973633: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 2928128 totalling 2.79MiB\n",
      "2024-04-13 21:00:37.973641: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 4718592 totalling 18.00MiB\n",
      "2024-04-13 21:00:37.973650: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 19 Chunks of size 9437184 totalling 171.00MiB\n",
      "2024-04-13 21:00:37.973658: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 14155776 totalling 13.50MiB\n",
      "2024-04-13 21:00:37.973667: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 5 Chunks of size 268435456 totalling 1.25GiB\n",
      "2024-04-13 21:00:37.973675: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 329515008 totalling 314.25MiB\n",
      "2024-04-13 21:00:37.973684: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1576009728 totalling 1.47GiB\n",
      "2024-04-13 21:00:37.973692: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 6303252480 totalling 5.87GiB\n",
      "2024-04-13 21:00:37.973700: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 9.12GiB\n",
      "2024-04-13 21:00:37.973708: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 15509553152 memory_limit_: 15509553152 available bytes: 0 curr_region_allocation_bytes_: 31019106304\n",
      "2024-04-13 21:00:37.973721: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                     15509553152\n",
      "InUse:                      9795492096\n",
      "MaxInUse:                  15008719360\n",
      "NumAllocs:                      269826\n",
      "MaxAllocSize:               6303252480\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-04-13 21:00:37.973739: W tensorflow/core/common_runtime/bfc_allocator.cc:491] **********************************************************__******_***______________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 55\u001b[0m\n\u001b[1;32m     50\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data\u001b[39;00m\n\u001b[1;32m     66\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained VGG16 model without the top classification layer\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(512, 512, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the pre-trained model\n",
    "model = Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(5, activation=\"softmax\"),  # Output layer with 5 classes\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",  # Use sparse categorical crossentropy for multi-class classification\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate class weights manually\n",
    "class_counts = np.bincount(y_train)\n",
    "total_samples = np.sum(class_counts)\n",
    "class_weights = {i: total_samples / count for i, count in enumerate(class_counts)}\n",
    "\n",
    "# Print class weights\n",
    "# print(\"Class Weights:\", class_weights)\n",
    "\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 17:21:27.928451: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 17:21:28.463144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14791 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 16, 16, 512)       14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               67109376  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,826,629\n",
      "Trainable params: 67,111,941\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "too many positional arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Compute class weights for imbalanced classes\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbalanced\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Define callbacks\u001b[39;00m\n\u001b[1;32m     41\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m     42\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     43\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_sig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/inspect.py:3112\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m (_VAR_KEYWORD, _KEYWORD_ONLY):\n\u001b[1;32m   3110\u001b[0m         \u001b[38;5;66;03m# Looks like we have no parameter for this positional\u001b[39;00m\n\u001b[1;32m   3111\u001b[0m         \u001b[38;5;66;03m# argument\u001b[39;00m\n\u001b[0;32m-> 3112\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3113\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoo many positional arguments\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _VAR_POSITIONAL:\n\u001b[1;32m   3116\u001b[0m         \u001b[38;5;66;03m# We have an '*args'-like argument, let's fill it with\u001b[39;00m\n\u001b[1;32m   3117\u001b[0m         \u001b[38;5;66;03m# all positional arguments we have left and move on to\u001b[39;00m\n\u001b[1;32m   3118\u001b[0m         \u001b[38;5;66;03m# the next phase\u001b[39;00m\n\u001b[1;32m   3119\u001b[0m         values \u001b[38;5;241m=\u001b[39m [arg_val]\n",
      "\u001b[0;31mTypeError\u001b[0m: too many positional arguments"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained VGG16 model without the top classification layer\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(512, 512, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the pre-trained model\n",
    "model = Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(5, activation=\"softmax\"),  # Output layer with 5 classes\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",  # Use sparse categorical crossentropy for multi-class classification\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate class weights manually\n",
    "class_counts = np.bincount(y_train)\n",
    "total_samples = np.sum(class_counts)\n",
    "class_weights = {i: total_samples / count for i, count in enumerate(class_counts)}\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN512 Model (no dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import (\n",
    "#     Conv2D,\n",
    "#     MaxPooling2D,\n",
    "#     Flatten,\n",
    "#     Dense,\n",
    "#     BatchNormalization,\n",
    "#     ZeroPadding2D,\n",
    "#     Activation,\n",
    "#     Dropout,\n",
    "# )\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# import math\n",
    "\n",
    "# # Define the CNN512 model architecture\n",
    "# model = Sequential()\n",
    "\n",
    "# # Input Layer (Zero Padding)\n",
    "# model.add(ZeroPadding2D(padding=(2, 2), input_shape=(512, 512, 3)))\n",
    "\n",
    "# # Layer 1, 2, 3\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 4\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 5, 6, 7\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 8\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 9, 10, 11\n",
    "# model.add(Conv2D(96, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 12\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 13, 14, 15\n",
    "# model.add(Conv2D(96, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 16\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 17, 18, 19\n",
    "# model.add(Conv2D(128, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 20\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 21, 22, 23\n",
    "# model.add(Conv2D(200, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 24\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 25\n",
    "# model.add(Flatten())\n",
    "\n",
    "# # Layer 26 (Dropout)\n",
    "# # model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 27, 28, 29\n",
    "# model.add(Dense(1000))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 30 (Dropout)\n",
    "# # model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 31, 32, 33\n",
    "# model.add(Dense(500))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 34 (Dropout)\n",
    "# # model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 35\n",
    "# model.add(Dense(5, activation=\"softmax\"))  # Assuming 4 classes for Retinopathy grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN512 Model (with dropout after FC layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import (\n",
    "#     Conv2D,\n",
    "#     MaxPooling2D,\n",
    "#     Flatten,\n",
    "#     Dense,\n",
    "#     BatchNormalization,\n",
    "#     ZeroPadding2D,\n",
    "#     Activation,\n",
    "#     Dropout,\n",
    "# )\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# import math\n",
    "\n",
    "# # Define the CNN512 model architecture\n",
    "# model = Sequential()\n",
    "\n",
    "# # Input Layer (Zero Padding)\n",
    "# model.add(ZeroPadding2D(padding=(2, 2), input_shape=(512, 512, 3)))\n",
    "\n",
    "# # Layer 1, 2, 3\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 4\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 5, 6, 7\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 8\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 9, 10, 11\n",
    "# model.add(Conv2D(96, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 12\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 13, 14, 15\n",
    "# model.add(Conv2D(96, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 16\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 17, 18, 19\n",
    "# model.add(Conv2D(128, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 20\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 21, 22, 23\n",
    "# model.add(Conv2D(200, (3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 24\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 25\n",
    "# model.add(Flatten())\n",
    "\n",
    "# # Layer 27, 28, 29\n",
    "# model.add(Dense(1000))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 31, 32, 33\n",
    "# model.add(Dense(500))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 35\n",
    "# model.add(Dense(5, activation=\"softmax\"))  # Assuming 4 classes for Retinopathy grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10019, 512, 512, 3)\n",
      "y_train shape: (10019,)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Convert to NumPy arrays if not already\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# # Check the shapes of the arrays\n",
    "# print(\"X_train shape:\", X_train.shape)\n",
    "# print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 07:23:33.368487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 07:23:33.752699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14791 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\n",
      "2024-04-13 07:23:34.208502: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7879262208 exceeds 10% of free system memory.\n",
      "2024-04-13 07:23:41.183477: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7879262208 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 105\u001b[0m\n\u001b[1;32m    102\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m LearningRateScheduler(lr_schedule)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Fit the model to the training data\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel512\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Assuming 10 epochs for training\u001b[39;49;00m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Assuming batch size of 32\u001b[39;49;00m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Learning rate scheduler callback\u001b[39;49;00m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Auto compute class weights\u001b[39;49;00m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Show training progress\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data\u001b[39;00m\n\u001b[1;32m    116\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model512\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1599\u001b[0m, in \u001b[0;36m_make_class_weight_map_fn\u001b[0;34m(class_weight)\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_class_weight_map_fn\u001b[39m(class_weight):\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies class weighting to a `Dataset`.\u001b[39;00m\n\u001b[1;32m   1587\u001b[0m \n\u001b[1;32m   1588\u001b[0m \u001b[38;5;124;03m    The `Dataset` is assumed to be in format `(x, y)` or `(x, y, sw)`, where\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;124;03m      weighting.\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1599\u001b[0m     class_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m()))\n\u001b[1;32m   1600\u001b[0m     expected_class_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(class_ids)))\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m class_ids \u001b[38;5;241m!=\u001b[39m expected_class_ids:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import (\n",
    "#     Conv2D,\n",
    "#     MaxPooling2D,\n",
    "#     Flatten,\n",
    "#     Dense,\n",
    "#     BatchNormalization,\n",
    "#     ZeroPadding2D,\n",
    "#     Activation,\n",
    "#     Dropout,\n",
    "# )\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# # Create the Sequential model\n",
    "# model512 = Sequential()\n",
    "\n",
    "# # Input Layer (Zero Padding)\n",
    "# model512.add(ZeroPadding2D(padding=(2, 2), input_shape=(512, 512, 3)))\n",
    "\n",
    "# # Layer 1\n",
    "# model512.add(Conv2D(32, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 2\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 3\n",
    "# model512.add(Conv2D(64, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 4\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 5\n",
    "# model512.add(Conv2D(96, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 6\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 7\n",
    "# model512.add(Conv2D(96, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 8\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 9\n",
    "# model512.add(Conv2D(128, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 10\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 11\n",
    "# model512.add(Conv2D(200, (3, 3)))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "\n",
    "# # Layer 12\n",
    "# model512.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Layer 13 (Dropout)\n",
    "# model512.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 14\n",
    "# model512.add(Dense(1000))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "# model512.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 15\n",
    "# model512.add(Dense(500))\n",
    "# model512.add(BatchNormalization())\n",
    "# model512.add(Activation(\"relu\"))\n",
    "# model512.add(Dropout(0.5))\n",
    "\n",
    "# # Layer 16 (Output Layer)\n",
    "# model512.add(Dense(5, activation=\"softmax\"))  # Assuming 5 classes for classification\n",
    "\n",
    "# # Define the optimizer with specified learning rate and momentum\n",
    "# learning_rate = 1e-1\n",
    "# optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "# # Compile the model with SGD optimizer and specified loss function\n",
    "# model512.compile(\n",
    "#     optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "\n",
    "# # Define the learning rate schedule\n",
    "# def lr_schedule(epoch):\n",
    "#     return learning_rate * math.pow(0.5, math.floor((1 + epoch) / 10))\n",
    "\n",
    "\n",
    "# # Define the learning rate scheduler\n",
    "# lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# # Fit the model to the training data\n",
    "# history = model512.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=10,  # Assuming 10 epochs for training\n",
    "#     batch_size=16,  # Assuming batch size of 32\n",
    "#     callbacks=[lr_scheduler],  # Learning rate scheduler callback\n",
    "#     class_weight=\"auto\",  # Auto compute class weights\n",
    "#     verbose=1,\n",
    "# )  # Show training progress\n",
    "\n",
    "# # Evaluate the model on the test data\n",
    "# test_loss, test_accuracy = model512.evaluate(X_test, y_test)\n",
    "\n",
    "# print(f\"Test Loss: {test_loss}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# # base learning rate\n",
    "# base_learning_rate = 1e-4\n",
    "# # maximum learning rate\n",
    "# max_learning_rate = 1e-2\n",
    "\n",
    "# # Create an instance of SGD optimizer with initial learning rate\n",
    "# optimizer = SGD(learning_rate=base_learning_rate, momentum=0.9, clipnorm=1.0)\n",
    "\n",
    "# # create class weight\n",
    "# classes = np.unique(y_train)\n",
    "# class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
    "# class_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "\n",
    "# # create triangular schedule\n",
    "# def triangular_schedule(epoch):\n",
    "#     \"\"\"Triangular learning rate scheduler.\"\"\"\n",
    "#     cycle_length = 10  # Define the length of a cycle\n",
    "#     cycle = math.floor(1 + epoch / (2 * cycle_length))\n",
    "#     x = abs(epoch / cycle_length - 2 * cycle + 1)\n",
    "#     lr = base_learning_rate + (max_learning_rate - base_learning_rate) * max(0, (1 - x))\n",
    "#     return lr\n",
    "\n",
    "\n",
    "# # When fitting the model, include the learning rate scheduler callback\n",
    "# lr_scheduler = LearningRateScheduler(triangular_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the top layer of the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 01:26:42.931320: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7879262208 exceeds 10% of free system memory.\n",
      "2024-04-13 01:26:47.177854: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7879262208 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 01:26:52.265105: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8902\n",
      "2024-04-13 01:26:52.381890: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-13 01:26:53.061359: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-13 01:26:53.061428: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 39s 115ms/step - loss: 1.8181 - accuracy: 0.2720 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.5985 - accuracy: 0.3644 - lr: 0.0011\n",
      "Epoch 3/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.4761 - accuracy: 0.4182 - lr: 0.0021\n",
      "Epoch 4/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.3889 - accuracy: 0.4297 - lr: 0.0031\n",
      "Epoch 5/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.3507 - accuracy: 0.4772 - lr: 0.0041\n",
      "Epoch 6/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.2664 - accuracy: 0.4996 - lr: 0.0050\n",
      "Epoch 7/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.1420 - accuracy: 0.5217 - lr: 0.0060\n",
      "Epoch 8/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 1.0190 - accuracy: 0.5637 - lr: 0.0070\n",
      "Epoch 9/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.8811 - accuracy: 0.5980 - lr: 0.0080\n",
      "Epoch 10/10\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.7290 - accuracy: 0.6512 - lr: 0.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b785b7340>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compile(\n",
    "#     optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "# print(\"Fitting the top layer of the model\")\n",
    "# model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=10,\n",
    "#     batch_size=32,\n",
    "#     class_weight=class_weight_dict,\n",
    "#     callbacks=[lr_scheduler],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 34ms/step - loss: 1.3069 - accuracy: 0.4674\n",
      "Test Accuracy: 0.46743908524513245\n"
     ]
    }
   ],
   "source": [
    "# # Evaluate the model\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "# print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
