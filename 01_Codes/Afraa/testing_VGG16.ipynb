{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 22:51:41.240733: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 22:51:41.398433: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-13 22:51:42.213525: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-13 22:51:42.213644: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-13 22:51:42.213663: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 22:51:49.387649: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 22:51:49.904564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14791 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variable for TensorFlow\n",
    "# os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configure GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth before initializing GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Handle potential errors here\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# Set seeds to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)  # For multi-GPU setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "    # Rotate the image by the specified angle\n",
    "    height, width = image.shape[:2]\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "def flip_image(image):\n",
    "    if random.choice([True, False]):\n",
    "        image = cv2.flip(image, 1)\n",
    "    if random.choice([True, False]):\n",
    "        image = cv2.flip(image, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def shear_image(image, shear_range):\n",
    "    height, width = image.shape[:2]\n",
    "    shear_value = random.uniform(-shear_range, shear_range)\n",
    "\n",
    "    if shear_value < 0:\n",
    "        shear_matrix = np.array([[1, -shear_value, 0], [0, 1, 0]])\n",
    "    else:\n",
    "        shear_matrix = np.array([[1, shear_value, 0], [0, 1, 0]])\n",
    "\n",
    "    sheared_image = cv2.warpAffine(image, shear_matrix, (width, height))\n",
    "    return sheared_image\n",
    "\n",
    "\n",
    "def translate_image(image, translate_range):\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    max_shift_x = int(width * 0.1)\n",
    "    max_shift_y = int(height * 0.1)\n",
    "\n",
    "    translate_x = random.randint(-max_shift_x, max_shift_x)\n",
    "    translate_y = random.randint(-max_shift_y, max_shift_y)\n",
    "\n",
    "    translation_matrix = np.array(\n",
    "        [[1, 0, translate_x], [0, 1, translate_y]], dtype=np.float32\n",
    "    )  # Ensure matrix type is float32\n",
    "\n",
    "    translated_image = cv2.warpAffine(image, translation_matrix, (width, height))\n",
    "\n",
    "    return translated_image\n",
    "\n",
    "\n",
    "def adjust_brightness(image, brightness_range):\n",
    "    brightness_factor = 1.0 + random.uniform(-brightness_range, brightness_range)\n",
    "    adjusted_image = np.clip(image * brightness_factor, 0.25, 255).astype(np.uint8)\n",
    "    return adjusted_image\n",
    "\n",
    "\n",
    "def augmented_fn(image):\n",
    "    angle = random.uniform(-35, 35)\n",
    "    image = rotate_image(image, angle)\n",
    "    image = flip_image(image)\n",
    "    image = shear_image(image, shear_range=0.15)\n",
    "    image = translate_image(image, translate_range=0.1)\n",
    "    image = adjust_brightness(image, brightness_range=0.25)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def apply_augmentation(image):\n",
    "    augmented_images = []\n",
    "    for _ in range(20):\n",
    "        augmented_image = augmented_fn(image)\n",
    "        augmented_images.append(augmented_image)\n",
    "    return np.array(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from file\n",
    "X_train_data = np.load(\n",
    "    \"/workspaces/Diabetic-Retinopathy/aws_s3/messidor_512/X_train.npy\"\n",
    ")\n",
    "X_test_data = np.load(\"/workspaces/Diabetic-Retinopathy/aws_s3/messidor_512/X_test.npy\")\n",
    "y_train_data = np.load(\n",
    "    \"/workspaces/Diabetic-Retinopathy/aws_s3/messidor_512/y_train.npy\"\n",
    ")\n",
    "y_test_data = np.load(\"/workspaces/Diabetic-Retinopathy/aws_s3/messidor_512/y_test.npy\")\n",
    "\n",
    "\n",
    "# Assign X_test data to X_train\n",
    "X_train = X_train_data\n",
    "X_test = X_test_data\n",
    "y_train = y_train_data\n",
    "y_test = y_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 16, 16, 512)       14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               67109376  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,826,629\n",
      "Trainable params: 67,111,941\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 22:55:55.103475: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2024-04-13 22:55:55.218564: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 15s 356ms/step - loss: 476.0885 - accuracy: 0.2796 - val_loss: 27.6922 - val_accuracy: 0.2232\n",
      "Epoch 2/25\n",
      "30/30 [==============================] - 9s 295ms/step - loss: 31.9178 - accuracy: 0.4312 - val_loss: 1.2998 - val_accuracy: 0.3605\n",
      "Epoch 3/25\n",
      "30/30 [==============================] - 9s 300ms/step - loss: 5.8389 - accuracy: 0.3430 - val_loss: 1.2471 - val_accuracy: 0.4335\n",
      "Epoch 4/25\n",
      "30/30 [==============================] - 9s 289ms/step - loss: 4.9319 - accuracy: 0.4011 - val_loss: 1.3513 - val_accuracy: 0.4893\n",
      "Epoch 5/25\n",
      "29/30 [============================>.] - ETA: 0s - loss: 4.5745 - accuracy: 0.4591"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained VGG16 model without the top classification layer\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(512, 512, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the pre-trained model\n",
    "model = Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(5, activation=\"softmax\"),  # Output layer with 5 classes\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",  # Use sparse categorical crossentropy for multi-class classification\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Calculate class weights manually\n",
    "class_counts = np.bincount(y_train)\n",
    "total_samples = np.sum(class_counts)\n",
    "class_weights = {i: total_samples / count for i, count in enumerate(class_counts)}\n",
    "\n",
    "# Print class weights\n",
    "# print(\"Class Weights:\", class_weights)\n",
    "\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
