{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Create the Data for adding to the S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "pd.set_option(\"mode.copy_on_write\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a local copy of the custom functions so that they can be changed as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, threshold=15, resize_flag=False, desired_size=(512, 512)):\n",
    "    # Convert image to numpy array\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Get the shape of the image\n",
    "    x_dim = img_np.shape[0]\n",
    "    y_dim = img_np.shape[1]\n",
    "\n",
    "    # Sum along the color axis (assuming the color axis is the third dimension)\n",
    "    pixel_sums = img_np.sum(axis=2)\n",
    "\n",
    "    # Sum along the x and y axes\n",
    "    x_arr = pixel_sums.sum(axis=1)\n",
    "    y_arr = pixel_sums.sum(axis=0)\n",
    "\n",
    "    # Find the first and last indices where the sum exceeds the threshold\n",
    "    x_start = np.where(x_arr > threshold * y_dim)[0][0]\n",
    "    x_end = np.where(x_arr > threshold * y_dim)[0][-1]\n",
    "\n",
    "    y_start = np.where(y_arr > threshold * x_dim)[0][0]\n",
    "    y_end = np.where(y_arr > threshold * x_dim)[0][-1]\n",
    "\n",
    "    # Crop the image\n",
    "    new_img = img_np[x_start:x_end, y_start:y_end]\n",
    "\n",
    "    # converting back to image\n",
    "    new_img = Image.fromarray(new_img)\n",
    "\n",
    "    # resizing the image\n",
    "    if resize_flag:\n",
    "        new_img = new_img.resize(desired_size)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, desired_size=(512, 512)):\n",
    "    # resizing the image\n",
    "    new_img = img.resize(desired_size)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# luminosity and noise removal function\n",
    "def luminosity_image(image_path, desired_size):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
    "    l_eq = clahe.apply(l)\n",
    "\n",
    "    # Merge back LAB channels\n",
    "    lab_eq = cv2.merge((l_eq, a, b))\n",
    "    enhanced_image = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Image noise removal using Gaussian filter\n",
    "    filtered_image = cv2.GaussianBlur(enhanced_image, (5, 5), 0)\n",
    "\n",
    "    # Convert to PIL image\n",
    "    filtered_image = Image.fromarray(filtered_image)\n",
    "\n",
    "    # Resize the image\n",
    "    filtered_image = resize_image(filtered_image, desired_size)\n",
    "\n",
    "    # # Save the preprocessed image\n",
    "    # image_name = os.path.basename(image_path)\n",
    "    # output_path = os.path.join(output_dir, image_name)\n",
    "    # cv2.imwrite(output_path, filtered_image)\n",
    "\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(img):\n",
    "    # Convert image to numpy array\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Calculate mean and standard deviation (std) channel-wise\n",
    "    mean_channels = np.mean(img_np, axis=(0, 1))\n",
    "    std_channels = np.std(img_np, axis=(0, 1))\n",
    "\n",
    "    # Normalize each channel separately\n",
    "    normalized_image = np.zeros_like(img_np, dtype=np.float32)\n",
    "    for channel in range(img_np.shape[2]):\n",
    "        normalized_image[:, :, channel] = (\n",
    "            img_np[:, :, channel] - mean_channels[channel]\n",
    "        ) / std_channels[channel]\n",
    "\n",
    "    # Scale values to be within [0, 255]\n",
    "    normalized_image = (\n",
    "        (normalized_image - np.min(normalized_image))\n",
    "        / (np.max(normalized_image) - np.min(normalized_image))\n",
    "        * 255\n",
    "    )\n",
    "\n",
    "    # Clip and return the normalized image\n",
    "    normalized_image = np.clip(normalized_image, 0, 255)\n",
    "    return normalized_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../../aws_s3/Raw_IDRID/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image name</th>\n",
       "      <th>Retinopathy grade</th>\n",
       "      <th>Risk of macular edema</th>\n",
       "      <th>Retinopathy grade new</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>IDRiD_186</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>IDRiD_106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>IDRiD_242</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>IDRiD_390</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>IDRiD_466</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image name  Retinopathy grade  Risk of macular edema   \\\n",
       "398  IDRiD_186                  2                       2   \n",
       "316  IDRiD_106                  2                       2   \n",
       "35   IDRiD_242                  2                       2   \n",
       "491  IDRiD_390                  4                       2   \n",
       "154  IDRiD_466                  4                       2   \n",
       "\n",
       "     Retinopathy grade new  split  \n",
       "398                      2  train  \n",
       "316                      2  train  \n",
       "35                       2  train  \n",
       "491                      3  train  \n",
       "154                      3  train  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the mapping file\n",
    "\n",
    "mapping = pd.read_csv(source + \"train_split_key_recoded.csv\")\n",
    "mapping.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating that we have correct number of files in the sub-directories\n",
    "test_size = len(mapping[mapping[\"split\"] == \"test\"])\n",
    "train_size = len(mapping[mapping[\"split\"] == \"train\"])\n",
    "\n",
    "# test files\n",
    "assert len(os.listdir(source + \"test/\")) == test_size\n",
    "\n",
    "# train files\n",
    "assert len(os.listdir(source + \"train/\")) == train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here the files are simply resized to 512x512 and 224x224 and saved in the respective directories as numpy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"../../aws_s3_temp/Raw/\"\n",
    "desired_sizes = [(512, 512), (224, 224)]\n",
    "out_directories = [\"Idrid_512_Raw\", \"Idrid_224_Raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    desired_size = desired_sizes[i]\n",
    "    out_directory = out_directories[i]\n",
    "\n",
    "    # delete the directory if it already exists\n",
    "    if os.path.exists(base_directory + out_directory):\n",
    "        os.system(\"rm -rf \" + base_directory + out_directory)\n",
    "    os.mkdir(base_directory + out_directory)\n",
    "\n",
    "    # creating the 4 arrays for train and test data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for file in os.listdir(source + \"train/\"):\n",
    "        image_path = source + \"train/\" + file\n",
    "        file_name = file.split(\".\")[0]\n",
    "\n",
    "        # validate that the file exists in the mapping, is Train File and is included\n",
    "        assert mapping[mapping[\"Image name\"] == file_name][\"split\"].values[0] == \"train\"\n",
    "\n",
    "        # Get the label\n",
    "        label = mapping[mapping[\"Image name\"] == file_name][\n",
    "            \"Retinopathy grade new\"\n",
    "        ].values[0]\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # resize the image\n",
    "        image = resize_image(image, desired_size)\n",
    "\n",
    "        # convert to numpy array\n",
    "        img_np = np.array(image)\n",
    "\n",
    "        # Append the image and label to the training data\n",
    "        X_train.append(img_np)\n",
    "        y_train.append(label)\n",
    "\n",
    "    # repeating process for test data\n",
    "    for file in os.listdir(source + \"test/\"):\n",
    "        image_path = source + \"test/\" + file\n",
    "\n",
    "        file_name = file.split(\".\")[0]\n",
    "\n",
    "        # validate that the file exists in the mapping, is Train File and is included\n",
    "        assert mapping[mapping[\"Image name\"] == file_name][\"split\"].values[0] == \"test\"\n",
    "\n",
    "        # Get the label\n",
    "        label = mapping[mapping[\"Image name\"] == file_name][\n",
    "            \"Retinopathy grade new\"\n",
    "        ].values[0]\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # resize the image\n",
    "        image = resize_image(image, desired_size)\n",
    "\n",
    "        # convert to numpy array\n",
    "        img_np = np.array(image)\n",
    "\n",
    "        # Append the image and label to the training data\n",
    "        X_test.append(img_np)\n",
    "        y_test.append(label)\n",
    "\n",
    "    # validating the dimensions of the arrays\n",
    "    assert len(X_train) == train_size\n",
    "    assert len(y_train) == train_size\n",
    "    assert len(X_test) == test_size\n",
    "    assert len(y_test) == test_size\n",
    "\n",
    "    # convertin the arrays to numpy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # validating the dimensions of the arrays\n",
    "    assert X_train.shape == (train_size, desired_size[0], desired_size[1], 3)\n",
    "    assert y_train.shape == (train_size,)\n",
    "    assert X_test.shape == (test_size, desired_size[0], desired_size[1], 3)\n",
    "    assert y_test.shape == (test_size,)\n",
    "\n",
    "    # saving the numpy arrays\n",
    "    np.save(base_directory + out_directory + \"/X_train.npy\", X_train)\n",
    "    np.save(base_directory + out_directory + \"/y_train.npy\", y_train)\n",
    "    np.save(base_directory + out_directory + \"/X_test.npy\", X_test)\n",
    "    np.save(base_directory + out_directory + \"/y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Enhancement and Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"../../aws_s3_temp/IENR/\"\n",
    "desired_sizes = [(512, 512), (224, 224)]\n",
    "out_directories = [\"Idrid_512_IENR\", \"Idrid_224_IENR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    desired_size = desired_sizes[i]\n",
    "    out_directory = out_directories[i]\n",
    "\n",
    "    # delete the directory if it already exists\n",
    "    if os.path.exists(base_directory + out_directory):\n",
    "        os.system(\"rm -rf \" + base_directory + out_directory)\n",
    "    os.mkdir(base_directory + out_directory)\n",
    "\n",
    "    # creating the 4 arrays for train and test data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for file in os.listdir(source + \"train/\"):\n",
    "        image_path = source + \"train/\" + file\n",
    "        file_name = file.split(\".\")[0]\n",
    "\n",
    "        # validate that the file exists in the mapping, is Train File and is included\n",
    "        assert mapping[mapping[\"Image name\"] == file_name][\"split\"].values[0] == \"train\"\n",
    "\n",
    "        # Get the label\n",
    "        label = mapping[mapping[\"Image name\"] == file_name][\n",
    "            \"Retinopathy grade new\"\n",
    "        ].values[0]\n",
    "\n",
    "        image = luminosity_image(image_path, desired_size)\n",
    "\n",
    "        # convert to numpy array\n",
    "        img_np = np.array(image)\n",
    "\n",
    "        # Append the image and label to the training data\n",
    "        X_train.append(img_np)\n",
    "        y_train.append(label)\n",
    "\n",
    "    # repeating process for test data\n",
    "    for file in os.listdir(source + \"test/\"):\n",
    "        image_path = source + \"test/\" + file\n",
    "        file_name = file.split(\".\")[0]\n",
    "\n",
    "        # validate that the file exists in the mapping, is Train File and is included\n",
    "        assert mapping[mapping[\"Image name\"] == file_name][\"split\"].values[0] == \"test\"\n",
    "\n",
    "        # Get the label\n",
    "        label = mapping[mapping[\"Image name\"] == file_name][\n",
    "            \"Retinopathy grade new\"\n",
    "        ].values[0]\n",
    "\n",
    "        image = luminosity_image(image_path, desired_size)\n",
    "\n",
    "        # convert to numpy array\n",
    "        img_np = np.array(image)\n",
    "\n",
    "        # Append the image and label to the training data\n",
    "        X_test.append(img_np)\n",
    "        y_test.append(label)\n",
    "\n",
    "    # validating the dimensions of the arrays\n",
    "    assert len(X_train) == train_size\n",
    "    assert len(y_train) == train_size\n",
    "    assert len(X_test) == test_size\n",
    "    assert len(y_test) == test_size\n",
    "\n",
    "    # convertin the arrays to numpy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # validating the dimensions of the arrays\n",
    "    assert X_train.shape == (train_size, desired_size[0], desired_size[1], 3)\n",
    "    assert y_train.shape == (train_size,)\n",
    "    assert X_test.shape == (test_size, desired_size[0], desired_size[1], 3)\n",
    "    assert y_test.shape == (test_size,)\n",
    "\n",
    "    # saving the numpy arrays\n",
    "    np.save(base_directory + out_directory + \"/X_train.npy\", X_train)\n",
    "    np.save(base_directory + out_directory + \"/y_train.npy\", y_train)\n",
    "    np.save(base_directory + out_directory + \"/X_test.npy\", X_test)\n",
    "    np.save(base_directory + out_directory + \"/y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"../../aws_s3_temp/CN/\"\n",
    "desired_sizes = [(512, 512), (224, 224)]\n",
    "out_directories = [\"Idrid_512_CN\", \"Idrid_224_CN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    desired_size = desired_sizes[i]\n",
    "    out_directory = out_directories[i]\n",
    "\n",
    "    # delete the directory if it already exists\n",
    "    if os.path.exists(base_directory + out_directory):\n",
    "        os.system(\"rm -rf \" + base_directory + out_directory)\n",
    "    os.mkdir(base_directory + out_directory)\n",
    "\n",
    "    # creating the 4 arrays for train and test data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for file in os.listdir(source + \"train/\"):\n",
    "        image_path = source + \"train/\" + file\n",
    "        file_name = file.split(\".\")[0]\n",
    "\n",
    "        # validate that the file exists in the mapping, is Train File and is included\n",
    "        assert mapping[mapping[\"Image name\"] == file_name][\"split\"].values[0] == \"train\"\n",
    "\n",
    "        # Get the label\n",
    "        label = mapping[mapping[\"Image name\"] == file_name][\n",
    "            \"Retinopathy grade new\"\n",
    "        ].values[0]\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # resize the image\n",
    "        image = resize_image(image, desired_size)\n",
    "\n",
    "        # do color normalization\n",
    "        img_np = normalize_image(image)\n",
    "\n",
    "        # Append the image and label to the training data\n",
    "        X_train.append(img_np)\n",
    "        y_train.append(label)\n",
    "\n",
    "    # repeating process for test data\n",
    "    for file in os.listdir(source + \"test/\"):\n",
    "        image_path = source + \"test/\" + file\n",
    "        file_name = file.split(\".\")[0]\n",
    "\n",
    "        # validate that the file exists in the mapping, is Train File and is included\n",
    "        assert mapping[mapping[\"Image name\"] == file_name][\"split\"].values[0] == \"test\"\n",
    "\n",
    "        # Get the label\n",
    "        label = mapping[mapping[\"Image name\"] == file_name][\n",
    "            \"Retinopathy grade new\"\n",
    "        ].values[0]\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # resize the image\n",
    "        image = resize_image(image, desired_size)\n",
    "\n",
    "        # do color normalization\n",
    "        img_np = normalize_image(image)\n",
    "\n",
    "        # Append the image and label to the training data\n",
    "        X_test.append(img_np)\n",
    "        y_test.append(label)\n",
    "\n",
    "    # validating the dimensions of the arrays\n",
    "    assert len(X_train) == train_size\n",
    "    assert len(y_train) == train_size\n",
    "    assert len(X_test) == test_size\n",
    "    assert len(y_test) == test_size\n",
    "\n",
    "    # convertin the arrays to numpy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # validating the dimensions of the arrays\n",
    "    assert X_train.shape == (train_size, desired_size[0], desired_size[1], 3)\n",
    "    assert y_train.shape == (train_size,)\n",
    "    assert X_test.shape == (test_size, desired_size[0], desired_size[1], 3)\n",
    "    assert y_test.shape == (test_size,)\n",
    "\n",
    "    # saving the numpy arrays\n",
    "    np.save(base_directory + out_directory + \"/X_train.npy\", X_train)\n",
    "    np.save(base_directory + out_directory + \"/y_train.npy\", y_train)\n",
    "    np.save(base_directory + out_directory + \"/X_test.npy\", X_test)\n",
    "    np.save(base_directory + out_directory + \"/y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"../../aws_s3_temp/Crop/\"\n",
    "desired_sizes = [(512, 512), (224, 224)]\n",
    "out_directories = [\"Idrid_512_Crop\", \"Idrid_224_Crop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    desired_size = desired_sizes[i]\n",
    "    out_directory = out_directories[i]\n",
    "\n",
    "    # delete the directory if it already exists\n",
    "    if os.path.exists(base_directory + out_directory):\n",
    "        os.system(\"rm -rf \" + base_directory + out_directory)\n",
    "    os.mkdir(base_directory + out_directory)\n",
    "\n",
    "    # creating the 4 arrays for train and test data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for file in os.listdir(source + \"train/\"):\n",
    "        image_path = source + \"train/\" + file\n",
    "        file_name = file.split(\".\")[0]\n",
    "\n",
    "        # validate that the file exists in the mapping, is Train File and is included\n",
    "        assert mapping[mapping[\"Image name\"] == file_name][\"split\"].values[0] == \"train\"\n",
    "\n",
    "        # Get the label\n",
    "        label = mapping[mapping[\"Image name\"] == file_name][\n",
    "            \"Retinopathy grade new\"\n",
    "        ].values[0]\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # crop the image\n",
    "        image = crop_image(\n",
    "            image, threshold=15, resize_flag=True, desired_size=desired_size\n",
    "        )\n",
    "\n",
    "        # convert to numpy array\n",
    "        img_np = np.array(image)\n",
    "\n",
    "        # Append the image and label to the training data\n",
    "        X_train.append(img_np)\n",
    "        y_train.append(label)\n",
    "\n",
    "    # repeating process for test data\n",
    "    for file in os.listdir(source + \"test/\"):\n",
    "        image_path = source + \"test/\" + file\n",
    "        file_name = file.split(\".\")[0]\n",
    "\n",
    "        # validate that the file exists in the mapping, is Train File and is included\n",
    "        assert mapping[mapping[\"Image name\"] == file_name][\"split\"].values[0] == \"test\"\n",
    "\n",
    "        # Get the label\n",
    "        label = mapping[mapping[\"Image name\"] == file_name][\n",
    "            \"Retinopathy grade new\"\n",
    "        ].values[0]\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # crop the image\n",
    "        image = crop_image(\n",
    "            image, threshold=15, resize_flag=True, desired_size=desired_size\n",
    "        )\n",
    "\n",
    "        # convert to numpy array\n",
    "        img_np = np.array(image)\n",
    "\n",
    "        # Append the image and label to the training data\n",
    "        X_test.append(img_np)\n",
    "        y_test.append(label)\n",
    "\n",
    "    # validating the dimensions of the arrays\n",
    "    assert len(X_train) == train_size\n",
    "    assert len(y_train) == train_size\n",
    "    assert len(X_test) == test_size\n",
    "    assert len(y_test) == test_size\n",
    "\n",
    "    # convertin the arrays to numpy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # validating the dimensions of the arrays\n",
    "    assert X_train.shape == (train_size, desired_size[0], desired_size[1], 3)\n",
    "    assert y_train.shape == (train_size,)\n",
    "    assert X_test.shape == (test_size, desired_size[0], desired_size[1], 3)\n",
    "    assert y_test.shape == (test_size,)\n",
    "\n",
    "    # saving the numpy arrays\n",
    "    np.save(base_directory + out_directory + \"/X_train.npy\", X_train)\n",
    "    np.save(base_directory + out_directory + \"/y_train.npy\", y_train)\n",
    "    np.save(base_directory + out_directory + \"/X_test.npy\", X_test)\n",
    "    np.save(base_directory + out_directory + \"/y_test.npy\", y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
